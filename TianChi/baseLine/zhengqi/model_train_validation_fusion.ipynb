{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练-验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r'E:\\DataSet\\Tianchi\\zhengqi\\zhengqi_train.txt'\n",
    "test_path = r'E:\\DataSet\\Tianchi\\zhengqi\\zhengqi_test.txt'\n",
    "\n",
    "train_data = pd.read_csv(train_path, delimiter=\"\\t\", encoding='utf-8')\n",
    "test_data = pd.read_csv(test_path, delimiter=\"\\t\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>V35</th>\n",
       "      <th>V36</th>\n",
       "      <th>V37</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "      <td>2888.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.690528</td>\n",
       "      <td>0.735521</td>\n",
       "      <td>0.593745</td>\n",
       "      <td>0.606301</td>\n",
       "      <td>0.639876</td>\n",
       "      <td>0.607801</td>\n",
       "      <td>0.735418</td>\n",
       "      <td>0.741337</td>\n",
       "      <td>0.702012</td>\n",
       "      <td>0.894246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401715</td>\n",
       "      <td>0.634030</td>\n",
       "      <td>0.760517</td>\n",
       "      <td>0.631794</td>\n",
       "      <td>0.459255</td>\n",
       "      <td>0.484465</td>\n",
       "      <td>0.734850</td>\n",
       "      <td>0.336306</td>\n",
       "      <td>0.527854</td>\n",
       "      <td>0.126353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.143747</td>\n",
       "      <td>0.133738</td>\n",
       "      <td>0.145844</td>\n",
       "      <td>0.151302</td>\n",
       "      <td>0.119550</td>\n",
       "      <td>0.193919</td>\n",
       "      <td>0.141872</td>\n",
       "      <td>0.137111</td>\n",
       "      <td>0.129082</td>\n",
       "      <td>0.067047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141644</td>\n",
       "      <td>0.125338</td>\n",
       "      <td>0.110903</td>\n",
       "      <td>0.139979</td>\n",
       "      <td>0.099782</td>\n",
       "      <td>0.101353</td>\n",
       "      <td>0.122917</td>\n",
       "      <td>0.123733</td>\n",
       "      <td>0.153423</td>\n",
       "      <td>0.983966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.625465</td>\n",
       "      <td>0.695419</td>\n",
       "      <td>0.497279</td>\n",
       "      <td>0.515165</td>\n",
       "      <td>0.586328</td>\n",
       "      <td>0.497566</td>\n",
       "      <td>0.659249</td>\n",
       "      <td>0.682314</td>\n",
       "      <td>0.653453</td>\n",
       "      <td>0.878743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300053</td>\n",
       "      <td>0.586993</td>\n",
       "      <td>0.722656</td>\n",
       "      <td>0.565408</td>\n",
       "      <td>0.409037</td>\n",
       "      <td>0.454490</td>\n",
       "      <td>0.684936</td>\n",
       "      <td>0.279760</td>\n",
       "      <td>0.427112</td>\n",
       "      <td>-0.350250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.727076</td>\n",
       "      <td>0.766264</td>\n",
       "      <td>0.609155</td>\n",
       "      <td>0.609933</td>\n",
       "      <td>0.652940</td>\n",
       "      <td>0.642456</td>\n",
       "      <td>0.767115</td>\n",
       "      <td>0.774045</td>\n",
       "      <td>0.728557</td>\n",
       "      <td>0.909110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385611</td>\n",
       "      <td>0.633755</td>\n",
       "      <td>0.782330</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.454518</td>\n",
       "      <td>0.499949</td>\n",
       "      <td>0.755580</td>\n",
       "      <td>0.349860</td>\n",
       "      <td>0.519532</td>\n",
       "      <td>0.313000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.783922</td>\n",
       "      <td>0.812642</td>\n",
       "      <td>0.694342</td>\n",
       "      <td>0.714174</td>\n",
       "      <td>0.712185</td>\n",
       "      <td>0.759266</td>\n",
       "      <td>0.835613</td>\n",
       "      <td>0.836958</td>\n",
       "      <td>0.781029</td>\n",
       "      <td>0.909110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488154</td>\n",
       "      <td>0.694136</td>\n",
       "      <td>0.824949</td>\n",
       "      <td>0.714950</td>\n",
       "      <td>0.504261</td>\n",
       "      <td>0.511365</td>\n",
       "      <td>0.785260</td>\n",
       "      <td>0.414511</td>\n",
       "      <td>0.622210</td>\n",
       "      <td>0.793250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.538000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                V0           V1           V2           V3           V4  \\\n",
       "count  2888.000000  2888.000000  2888.000000  2888.000000  2888.000000   \n",
       "mean      0.690528     0.735521     0.593745     0.606301     0.639876   \n",
       "std       0.143747     0.133738     0.145844     0.151302     0.119550   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.625465     0.695419     0.497279     0.515165     0.586328   \n",
       "50%       0.727076     0.766264     0.609155     0.609933     0.652940   \n",
       "75%       0.783922     0.812642     0.694342     0.714174     0.712185   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "                V5           V6           V7           V8           V9  ...  \\\n",
       "count  2888.000000  2888.000000  2888.000000  2888.000000  2888.000000  ...   \n",
       "mean      0.607801     0.735418     0.741337     0.702012     0.894246  ...   \n",
       "std       0.193919     0.141872     0.137111     0.129082     0.067047  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.497566     0.659249     0.682314     0.653453     0.878743  ...   \n",
       "50%       0.642456     0.767115     0.774045     0.728557     0.909110  ...   \n",
       "75%       0.759266     0.835613     0.836958     0.781029     0.909110  ...   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "\n",
       "               V29          V30          V31          V32          V33  \\\n",
       "count  2888.000000  2888.000000  2888.000000  2888.000000  2888.000000   \n",
       "mean      0.401715     0.634030     0.760517     0.631794     0.459255   \n",
       "std       0.141644     0.125338     0.110903     0.139979     0.099782   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.300053     0.586993     0.722656     0.565408     0.409037   \n",
       "50%       0.385611     0.633755     0.782330     0.634615     0.454518   \n",
       "75%       0.488154     0.694136     0.824949     0.714950     0.504261   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               V34          V35          V36          V37       target  \n",
       "count  2888.000000  2888.000000  2888.000000  2888.000000  2888.000000  \n",
       "mean      0.484465     0.734850     0.336306     0.527854     0.126353  \n",
       "std       0.101353     0.122917     0.123733     0.153423     0.983966  \n",
       "min       0.000000     0.000000     0.000000     0.000000    -3.044000  \n",
       "25%       0.454490     0.684936     0.279760     0.427112    -0.350250  \n",
       "50%       0.499949     0.755580     0.349860     0.519532     0.313000  \n",
       "75%       0.511365     0.785260     0.414511     0.622210     0.793250  \n",
       "max       1.000000     1.000000     1.000000     1.000000     2.538000  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 数据归一化处理\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "feature_columns = [col for col in train_data.columns if col not in  ['target']]\n",
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler.fit(train_data[feature_columns])\n",
    "train_data_scaler = min_max_scaler.transform(train_data[feature_columns])\n",
    "test_data_scaler = min_max_scaler.transform(test_data[feature_columns])\n",
    "train_data_scaler = pd.DataFrame(train_data_scaler)\n",
    "test_data_scaler= pd.DataFrame(test_data_scaler)\n",
    "train_data_scaler.columns = feature_columns\n",
    "train_data_scaler['target'] = train_data['target']\n",
    "test_data_scaler.columns = feature_columns\n",
    "# display(train_data_scaler.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca 降维，保留16个特征\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=16)\n",
    "new_train_pca_16 = pca.fit_transform(train_data_scaler.iloc[:, :-1])\n",
    "new_test_pca_16 = pca.fit_transform(test_data_scaler)\n",
    "new_train_pca_16 = pd.DataFrame(new_train_pca_16)\n",
    "new_test_pca_16 = pd.DataFrame(new_test_pca_16)\n",
    "new_train_pca_16['target'] = train_data_scaler['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据进行切分\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "new_train_pca_16 = new_train_pca_16.fillna(0)\n",
    "train = new_train_pca_16[new_test_pca_16.columns]\n",
    "target = new_train_pca_16['target']\n",
    "\n",
    "# train_test_split?\n",
    "train_data, test_data, train_target, test_target = train_test_split(train, target, test_size=0.2, random_state=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDRegressor train score:  0.15145464727954538\n",
      "SGDRegressor test score:  0.1557395424638947\n"
     ]
    }
   ],
   "source": [
    "# 欠拟合\n",
    "clf = SGDRegressor(max_iter=500, tol=1e-2)\n",
    "clf.fit(train_data, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "print('SGDRegressor train score: ', score_train)\n",
    "print('SGDRegressor test score: ', score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolynomialFeatures 5 train score:  0.13235408041938118\n",
      "PolynomialFeatures 5  test score:  0.14476785647048604\n"
     ]
    }
   ],
   "source": [
    "# 过拟合\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# PolynomialFeatures?\n",
    "poly = PolynomialFeatures(degree=5)\n",
    "train_data_poly = poly.fit_transform(train_data)\n",
    "test_data_poly = poly.fit_transform(test_data)\n",
    "clf = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "clf.fit(train_data_poly, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data_poly))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data_poly))\n",
    "print('PolynomialFeatures 5 train score: ', score_train)\n",
    "print('PolynomialFeatures 5  test score: ', score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolynomialFeatures 5 train score:  0.1340909154248941\n",
      "PolynomialFeatures 5  test score:  0.1425142188842414\n"
     ]
    }
   ],
   "source": [
    "# 正常拟合\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "train_data_poly = poly.fit_transform(train_data)\n",
    "test_data_poly = poly.fit_transform(test_data)\n",
    "clf = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "clf.fit(train_data_poly, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data_poly))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data_poly))\n",
    "print('PolynomialFeatures 5 train score: ', score_train)\n",
    "print('PolynomialFeatures 5  test score: ', score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 train score:  0.1351862901894467\n",
      "L2 test score:  0.14339244273112178\n"
     ]
    }
   ],
   "source": [
    "# 模型正则化\n",
    "# L2范数\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "train_data_poly = poly.fit_transform(train_data)\n",
    "test_data_poly = poly.fit_transform(test_data)\n",
    "clf = SGDRegressor(max_iter=1000, tol=1e-3, penalty='L2')\n",
    "clf.fit(train_data_poly, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data_poly))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data_poly))\n",
    "print('L2 train score: ', score_train)\n",
    "print('L2 test score: ', score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 train score:  0.13520502643322446\n",
      "L2 test score:  0.14307212748858583\n"
     ]
    }
   ],
   "source": [
    "# L1范数\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "train_data_poly = poly.fit_transform(train_data)\n",
    "test_data_poly = poly.fit_transform(test_data)\n",
    "clf = SGDRegressor(max_iter=1000, tol=1e-3, penalty='L1')\n",
    "clf.fit(train_data_poly, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data_poly))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data_poly))\n",
    "print('L1 train score: ', score_train)\n",
    "print('L1 test score: ', score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 train score:  0.1342818629360411\n",
      "L2 test score:  0.14240448231638014\n"
     ]
    }
   ],
   "source": [
    "# 弹性网络\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "train_data_poly = poly.fit_transform(train_data)\n",
    "test_data_poly = poly.fit_transform(test_data)\n",
    "clf = SGDRegressor(max_iter=1000, tol=1e-3, penalty='elasticnet')\n",
    "clf.fit(train_data_poly, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data_poly))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data_poly))\n",
    "print('elasticnet train score: ', score_train)\n",
    "print('elasticnet test score: ', score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉验证\n",
    "# 简单交叉验证\n",
    "clf = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "clf.fit(train_data, train_target)\n",
    "score_train = mean_squared_error(train_target, clf.predict(train_data))\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "print('SGDRegressor train score: ', score_train)\n",
    "print('SGDRegressor test score: ', score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 折 SGDRegressor train score:  0.9474942105521872\n",
      "0 折 SGDRegressor test score:  0.9065034130847645\n",
      "1 折 SGDRegressor train score:  0.9462105912668638\n",
      "1 折 SGDRegressor test score:  1.1021441017004299\n",
      "2 折 SGDRegressor train score:  0.9462727757960594\n",
      "2 折 SGDRegressor test score:  0.925211732395715\n",
      "(2888, 16)\n",
      "[   0    1    2 ... 2885 2886 2887]\n",
      "[1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747\n",
      " 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761\n",
      " 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775\n",
      " 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789\n",
      " 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803\n",
      " 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817\n",
      " 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831\n",
      " 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845\n",
      " 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859\n",
      " 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873\n",
      " 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887\n",
      " 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901\n",
      " 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915\n",
      " 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929\n",
      " 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943\n",
      " 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957\n",
      " 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971\n",
      " 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985\n",
      " 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999\n",
      " 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013\n",
      " 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027\n",
      " 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041\n",
      " 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055\n",
      " 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069\n",
      " 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083\n",
      " 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097\n",
      " 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111\n",
      " 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125\n",
      " 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139\n",
      " 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153\n",
      " 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167\n",
      " 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181\n",
      " 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195\n",
      " 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209\n",
      " 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223\n",
      " 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237\n",
      " 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251\n",
      " 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265\n",
      " 2266 2267 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279\n",
      " 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293\n",
      " 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307\n",
      " 2308 2309 2310]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2311, 2310]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-d92c59365118>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_taret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGDRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mscore_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mscore_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\devtools\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m   1216\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m                          \u001b[0mintercept_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1218\u001b[1;33m                          sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\devtools\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m   1176\u001b[0m         self._partial_fit(X, y, alpha, C, loss, learning_rate,\n\u001b[0;32m   1177\u001b[0m                           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                           intercept_init)\n\u001b[0m\u001b[0;32m   1179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m         if (self.tol is not None and self.tol > -np.inf\n",
      "\u001b[1;32md:\\devtools\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m   1097\u001b[0m                      max_iter, sample_weight, coef_init, intercept_init):\n\u001b[0;32m   1098\u001b[0m         X, y = check_X_y(X, y, \"csr\", copy=False, order='C', dtype=np.float64,\n\u001b[1;32m-> 1099\u001b[1;33m                          accept_large_sparse=False)\n\u001b[0m\u001b[0;32m   1100\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\devtools\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\devtools\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2311, 2310]"
     ]
    }
   ],
   "source": [
    "# K折交叉验证\n",
    "from sklearn.model_selection import KFold\n",
    "# ValueError: Found input variables with inconsistent numbers of samples: [2311, 2310]\n",
    "\n",
    "# kf = KFold(n_splits=5)\n",
    "# for k, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "#     if (k == 3):\n",
    "#         print(train.shape)\n",
    "#         print(train_index)\n",
    "#         print(test_index)\n",
    "#     train_data, test_data, train_taret, test_target = train.values[train_index],train.values[test_index],target[train_index],target[test_index]\n",
    "#     clf = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "#     clf.fit(train_data, train_target)\n",
    "#     score_train = mean_squared_error(train_target, clf.predict(train_data))\n",
    "#     score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "#     print(k, '折', 'SGDRegressor train score: ', score_train)\n",
    "#     print(k, '折', 'SGDRegressor test score: ', score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2887, 2310]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-fd54433a1bc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_taret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGDRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mscore_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mscore_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\devtools\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m   1216\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m                          \u001b[0mintercept_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1218\u001b[1;33m                          sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\devtools\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m   1176\u001b[0m         self._partial_fit(X, y, alpha, C, loss, learning_rate,\n\u001b[0;32m   1177\u001b[0m                           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                           intercept_init)\n\u001b[0m\u001b[0;32m   1179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m         if (self.tol is not None and self.tol > -np.inf\n",
      "\u001b[1;32md:\\devtools\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m   1097\u001b[0m                      max_iter, sample_weight, coef_init, intercept_init):\n\u001b[0;32m   1098\u001b[0m         X, y = check_X_y(X, y, \"csr\", copy=False, order='C', dtype=np.float64,\n\u001b[1;32m-> 1099\u001b[1;33m                          accept_large_sparse=False)\n\u001b[0m\u001b[0;32m   1100\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\devtools\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\devtools\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2887, 2310]"
     ]
    }
   ],
   "source": [
    "# 留一法验证\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "# loo = LeaveOneOut()\n",
    "# # kf = KFold(n_splits=5)\n",
    "# for k, (train_index, test_index) in enumerate(loo.split(train)):\n",
    "#     train_data, test_data, train_taret, test_target = train.values[train_index],train.values[test_index],target[train_index],target[test_index]\n",
    "#     clf = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "#     clf.fit(train_data, train_target)\n",
    "#     score_train = mean_squared_error(train_target, clf.predict(train_data))\n",
    "#     score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "#     print(k, '折', 'SGDRegressor train score: ', score_train)\n",
    "#     print(k, '折', 'SGDRegressor test score: ', score_test)\n",
    "#     if k > 9:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor GridSearchCV test score 0.2559431927020715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_max_depth',\n",
       " 'param_n_estimators',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调参 穷举网格搜索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_target, test_target = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "randomFrestRegression = RandomForestRegressor()\n",
    "parameters = {'n_estimators': [50, 100, 200], 'max_depth': [1, 2, 3]}\n",
    "clf = GridSearchCV(randomFrestRegression, parameters, cv=5)\n",
    "clf.fit(train_data, train_target)\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "print('RandomForestRegressor GridSearchCV test score', score_test)\n",
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV GridSearchCV test score 0.19878427647218627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_max_depth',\n",
       " 'param_n_estimators',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 调参 随机搜索\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_target, test_target = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "randomFrestRegression = RandomForestRegressor()\n",
    "parameters = {'n_estimators': [50, 100, 200, 300], 'max_depth': [1, 2, 3, 4, 5]}\n",
    "clf = RandomizedSearchCV(randomFrestRegression, parameters, cv=5)\n",
    "clf.fit(train_data, train_target)\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "print('RandomizedSearchCV GridSearchCV test score', score_test)\n",
    "# sorted(clf.cv_results_.keys())\n",
    "# print(clf.best_params_)\n",
    "# {'n_estimators': 50, 'max_depth': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMRegressor GridSearchCV test score 0.15048537417492472\n",
      "LGBMRegressor best parameters:  {'learning_rate': 0.1, 'n_estimators': 40}\n"
     ]
    }
   ],
   "source": [
    "# 调参 随机搜索\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "\n",
    "train_data, test_data, train_target, test_target = train_test_split(train, target, test_size=0.2, random_state=0)\n",
    "clf = lgb.LGBMRegressor(num_leaves=31)\n",
    "# clf?\n",
    "parameters = {'learning_rate': [0.01, 0.1, 1], 'n_estimators': [20, 40]}\n",
    "clf = GridSearchCV(clf, parameters, cv=5)\n",
    "clf.fit(train_data, train_target)\n",
    "score_test = mean_squared_error(test_target, clf.predict(test_data))\n",
    "print('LGBMRegressor GridSearchCV test score', score_test)\n",
    "print('LGBMRegressor best parameters: ', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
