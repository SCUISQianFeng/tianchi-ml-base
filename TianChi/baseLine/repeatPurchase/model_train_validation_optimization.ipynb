{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T08:33:17.957898Z",
     "start_time": "2021-07-09T08:33:00.135086Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156518, 230) (156518,)\n",
      "(104346, 230) (156518,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9387710118260403"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  导入数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 读取前1000行\n",
    "# train_data = pd.read_csv('train_all.csv', nrows=1000)\n",
    "# test_data = pd.read_csv('test_all.csv', nrows=1000)\n",
    "\n",
    "# 读取全部数据\n",
    "train_data = pd.read_csv('train_all.csv', nrows=None)\n",
    "test_data = pd.read_csv('test_all.csv', nrows=None)\n",
    "\n",
    "# 训练数据和测试数据处理\n",
    "feature_columns = [col for col in train_data.columns if col not in ['user_id', 'label']]\n",
    "train = train_data[feature_columns].values\n",
    "test = test_data[feature_columns].values\n",
    "target = train_data['label'].values\n",
    "\n",
    "\n",
    "# folds = 5\n",
    "# kf = KFold(n_splits=folds, shuffle=True, random_state=2021)\n",
    "\n",
    "# for idx, (train_index, test_index) for enumerate(kf.split(ttain)):\n",
    "#     train_x = train[train_index]\n",
    "#     train_y = target[train_index]\n",
    "#     test_x = test[test_index]\n",
    "#     test_y = target[test_index]\n",
    "\n",
    "\n",
    "# 切分数据\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.4, random_state=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_train.shape)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, n_jobs=-1)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T08:33:38.018432Z",
     "start_time": "2021-07-09T08:33:17.959917Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93885726 0.93885726 0.9388381  0.9388381  0.93885609]\n",
      "Accuracy: 0.94 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "# 简单验证\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, n_jobs=-1)\n",
    "# clf = clf.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(clf, train, target, cv=5)\n",
    "print(scores)\n",
    "print('Accuracy: %0.2f (+/- %0.2f)' % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T08:33:56.772766Z",
     "start_time": "2021-07-09T08:33:38.020431Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48423227 0.48423227 0.48422718 0.48422718 0.48423196]\n",
      "Accuracy: 0.48 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "# F1值进行评价\n",
    "\"\"\"\n",
    "'micro':Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "'micro':通过先计算总体的TP，FN和FP的数量，再计算F1\n",
    "'macro':Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "'macro':分布计算每个类别的F1，然后做平均（各类别F1的权重相同）\n",
    "\"\"\"\n",
    "\n",
    "scores = cross_val_score(clf, train, target, cv=5, scoring='f1_macro')\n",
    "print(scores)\n",
    "print('Accuracy: %0.2f (+/- %0.2f)' % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T08:34:19.289869Z",
     "start_time": "2021-07-09T08:33:56.773759Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93870432, 0.93828265, 0.93956044, 0.94040378, 0.93763097])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 交叉验证\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "cross_val_score(clf, train, target, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T08:34:30.953220Z",
     "start_time": "2021-07-09T08:34:19.290868Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9395089414064746\n",
      "1 0.9386272593103713\n",
      "2 0.9374005711766623\n",
      "3 0.9398539474440802\n",
      "4 0.9388560913900177\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "for k, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "    x_train, x_test, y_train, y_test = train[train_index], train[test_index], target[train_index], target[test_index]\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    print(k, clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T08:34:42.451630Z",
     "start_time": "2021-07-09T08:34:30.954201Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9388572633354417\n",
      "1 0.9388572633354417\n",
      "2 0.9388380963333525\n",
      "3 0.9388380963333525\n",
      "4 0.9388560913900177\n"
     ]
    }
   ],
   "source": [
    "# 分组切分数据\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "for k, (train_index, test_index) in enumerate(kf.split(train, target)):\n",
    "    x_train, x_test, y_train, y_test = train[train_index], train[test_index], target[train_index], target[test_index]\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    print(k, clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-09T08:33:00.136Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tune hyper-parameters for precision\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 模型调参\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.5, random_state=0)\n",
    "\n",
    "# model\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "tune_parameters = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [2, 5],\n",
    "    'max_features': ['log2', 'sqrt', 'int'],\n",
    "    'bootstrap': [True, False],\n",
    "    'warm_start': [True, False],\n",
    "}\n",
    "\n",
    "scores = ['precision']\n",
    "for score in scores:\n",
    "    print('Tune hyper-parameters for %s' % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(clf, tune_parameters, cv=5, scoring='%s_macro'  % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print('Best parameters set found on development set:')\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print('Grid scores on development set:')\n",
    "    print()\n",
    "    mean = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(mean, stds, clf.cv_results_):\n",
    "        print('%0.3f (+/-%0.03f) for %r' % (mean, std * 2, params))\n",
    "        print()\n",
    "        print('Detailed classification report:')\n",
    "        print()\n",
    "        print('The model is trained on the full develoment set.')\n",
    "        print('The scores are computed on the full evaluation set.')\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-09T08:33:00.137Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 混淆矩阵\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# label_name\n",
    "class_names = ['no-repeat', 'repeat']\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix,\n",
    "    Normalization can be applied by setting 'normalize=True'\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print('Confusion matrix normalization')\n",
    "    else:\n",
    "        print('Confusion matrix, Without normaliation')\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearset', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f if normalize else d'\n",
    "    thresh = cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j,\n",
    "                 i,\n",
    "                 format(cm[i, j], fmt),\n",
    "                 horizontilignment='center',\n",
    "                 color='white' if cm[i, j] > thresh else 'black')\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.tight_layout()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix,\n",
    "                      classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix,\n",
    "                      classes=class_names,\n",
    "                      normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-09T08:33:00.138Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 逻辑回归模型\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "clf = LogisticRegression(random_stat|e=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-09T08:33:00.140Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# KNN 模型\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-09T08:33:00.141Z"
    }
   },
   "outputs": [],
   "source": [
    "# 高斯贝叶斯模型\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 决策树模型\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Bagging模型\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = BaggingClassifier(base_estimator=KNeighborsClassifier(), max_samples=0.5, max_features=0.5).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 随机森林模型\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 极端森林模型\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# AdaBoost模型\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GBDT模型\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 集成学习\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 集成学习\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomforestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_scores\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_tranforms(train)\n",
    "y = target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "clf1 = LogisticRegression(solver='lbfgs', mutli_class='multinomial', random_state=0)\n",
    "clf2 = RandomforestClassifier(n_estimators=100, random_state=0)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "for clf, label in zip([clf1, clf2, clf4, eclf],\n",
    "                      ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_scores(clf, X,y, cv=5, scoring='accuracy')\n",
    "    print('Accuracy: %0.2f (+/-%0.2f) [%s]' % (scores.mean(), scores.std() * 2, label) )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "VotingClassifier?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-09T08:33:00.142Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-09T08:33:00.143Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bagging模型\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = BaggingClassifier(base_estimator=KNeighborsClassifier(), max_samples=0.5, max_features=0.5).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-09T08:33:00.144Z"
    }
   },
   "outputs": [],
   "source": [
    "# 随机森林模型\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-09T08:33:00.146Z"
    }
   },
   "outputs": [],
   "source": [
    "# 极端森林模型\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-09T08:33:00.147Z"
    }
   },
   "outputs": [],
   "source": [
    "# AdaBoost模型\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-09T08:33:00.148Z"
    }
   },
   "outputs": [],
   "source": [
    "# GBDT模型\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-09T08:33:00.149Z"
    }
   },
   "outputs": [],
   "source": [
    "# 集成学习\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-09T08:33:00.150Z"
    }
   },
   "outputs": [],
   "source": [
    "# 集成学习\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomforestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_scores\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_tranforms(train)\n",
    "y = target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "clf1 = LogisticRegression(solver='lbfgs', mutli_class='multinomial', random_state=0)\n",
    "clf2 = RandomforestClassifier(n_estimators=100, random_state=0)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "for clf, label in zip([clf1, clf2, clf4, eclf],\n",
    "                      ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_scores(clf, X,y, cv=5, scoring='accuracy')\n",
    "    print('Accuracy: %0.2f (+/-%0.2f) [%s]' % (scores.mean(), scores.std() * 2, label) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-09T08:33:00.151Z"
    }
   },
   "outputs": [],
   "source": [
    "VotingClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}