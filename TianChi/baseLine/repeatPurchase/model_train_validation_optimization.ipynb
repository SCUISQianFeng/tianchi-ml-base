{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T02:26:49.524883Z",
     "start_time": "2021-07-12T02:26:32.268771Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156518, 230) (156518,)\n",
      "(104346, 230) (156518,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9387710118260403"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  导入数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 读取前1000行\n",
    "# train_data = pd.read_csv('train_all.csv', nrows=1000)\n",
    "# test_data = pd.read_csv('test_all.csv', nrows=1000)\n",
    "\n",
    "# 读取全部数据\n",
    "train_data = pd.read_csv('train_all.csv', nrows=None)\n",
    "test_data = pd.read_csv('test_all.csv', nrows=None)\n",
    "\n",
    "# 训练数据和测试数据处理\n",
    "feature_columns = [col for col in train_data.columns if col not in ['user_id', 'label']]\n",
    "train = train_data[feature_columns].values\n",
    "test = test_data[feature_columns].values\n",
    "target = train_data['label'].values\n",
    "\n",
    "\n",
    "# folds = 5\n",
    "# kf = KFold(n_splits=folds, shuffle=True, random_state=2021)\n",
    "\n",
    "# for idx, (train_index, test_index) for enumerate(kf.split(ttain)):\n",
    "#     train_x = train[train_index]\n",
    "#     train_y = target[train_index]\n",
    "#     test_x = test[test_index]\n",
    "#     test_y = target[test_index]\n",
    "\n",
    "\n",
    "# 切分数据\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.4, random_state=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_train.shape)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, n_jobs=-1)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T02:27:09.464467Z",
     "start_time": "2021-07-12T02:26:49.526883Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93885726 0.93885726 0.9388381  0.9388381  0.93885609]\n",
      "Accuracy: 0.94 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "# 简单验证\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0, n_jobs=-1)\n",
    "# clf = clf.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(clf, train, target, cv=5)\n",
    "print(scores)\n",
    "print('Accuracy: %0.2f (+/- %0.2f)' % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T02:27:26.399770Z",
     "start_time": "2021-07-12T02:27:09.466466Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48423227 0.48423227 0.48422718 0.48422718 0.48423196]\n",
      "Accuracy: 0.48 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "# F1值进行评价\n",
    "\"\"\"\n",
    "'micro':Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
    "'micro':通过先计算总体的TP，FN和FP的数量，再计算F1\n",
    "'macro':Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.\n",
    "'macro':分布计算每个类别的F1，然后做平均（各类别F1的权重相同）\n",
    "\"\"\"\n",
    "\n",
    "scores = cross_val_score(clf, train, target, cv=5, scoring='f1_macro')\n",
    "print(scores)\n",
    "print('Accuracy: %0.2f (+/- %0.2f)' % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T02:27:48.012395Z",
     "start_time": "2021-07-12T02:27:26.401769Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93870432, 0.93828265, 0.93956044, 0.94040378, 0.93763097])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 交叉验证\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "cross_val_score(clf, train, target, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T02:27:59.856637Z",
     "start_time": "2021-07-12T02:27:48.013394Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9395089414064746\n",
      "1 0.9386272593103713\n",
      "2 0.9374005711766623\n",
      "3 0.9398539474440802\n",
      "4 0.9388560913900177\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "for k, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "    x_train, x_test, y_train, y_test = train[train_index], train[test_index], target[train_index], target[test_index]\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    print(k, clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T02:28:11.444977Z",
     "start_time": "2021-07-12T02:27:59.858619Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9388572633354417\n",
      "1 0.9388572633354417\n",
      "2 0.9388380963333525\n",
      "3 0.9388380963333525\n",
      "4 0.9388560913900177\n"
     ]
    }
   ],
   "source": [
    "# 分组切分数据\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "for k, (train_index, test_index) in enumerate(kf.split(train, target)):\n",
    "    x_train, x_test, y_train, y_test = train[train_index], train[test_index], target[train_index], target[test_index]\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    print(k, clf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T02:42:16.116414Z",
     "start_time": "2021-07-12T02:28:11.446976Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tune hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'bootstrap': True, 'max_depth': 2, 'max_features': 'log2', 'n_estimators': 50, 'warm_start': True}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.469 (+/-0.000) for 'mean_fit_time'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n",
      "0.469 (+/-0.000) for 'std_fit_time'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n",
      "0.469 (+/-0.000) for 'mean_score_time'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n",
      "0.469 (+/-0.000) for 'std_score_time'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n",
      "0.469 (+/-0.000) for 'param_bootstrap'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n",
      "0.469 (+/-0.000) for 'param_max_depth'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n",
      "0.469 (+/-0.000) for 'param_max_features'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n",
      "0.469 (+/-0.000) for 'param_n_estimators'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n",
      "0.469 (+/-0.000) for 'param_warm_start'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n",
      "0.469 (+/-0.000) for 'params'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n",
      "0.469 (+/-0.000) for 'split0_test_score'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n",
      "0.469 (+/-0.000) for 'split1_test_score'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n",
      "nan (+/-nan) for 'split2_test_score'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n",
      "nan (+/-nan) for 'split3_test_score'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n",
      "nan (+/-nan) for 'split4_test_score'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n",
      "nan (+/-nan) for 'mean_test_score'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n",
      "nan (+/-nan) for 'std_test_score'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n",
      "nan (+/-nan) for 'rank_test_score'\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full develoment set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      1.00      0.97    122462\n",
      "         1.0       0.00      0.00      0.00      7970\n",
      "\n",
      "    accuracy                           0.94    130432\n",
      "   macro avg       0.47      0.50      0.48    130432\n",
      "weighted avg       0.88      0.94      0.91    130432\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 模型调参\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.5, random_state=0)\n",
    "\n",
    "# model\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "tune_parameters = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [2, 5],\n",
    "    'max_features': ['log2', 'sqrt', 'int'],\n",
    "    'bootstrap': [True, False],\n",
    "    'warm_start': [True, False],\n",
    "}\n",
    "\n",
    "scores = ['precision']\n",
    "for score in scores:\n",
    "    print('Tune hyper-parameters for %s' % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(clf, tune_parameters, cv=5, scoring='%s_macro'  % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print('Best parameters set found on development set:')\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print('Grid scores on development set:')\n",
    "    print()\n",
    "    mean = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(mean, stds, clf.cv_results_):\n",
    "        print('%0.3f (+/-%0.03f) for %r' % (mean, std * 2, params))\n",
    "        print()\n",
    "        print('Detailed classification report:')\n",
    "        print()\n",
    "        print('The model is trained on the full develoment set.')\n",
    "        print('The scores are computed on the full evaluation set.')\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T05:54:46.708925Z",
     "start_time": "2021-07-12T05:54:27.560868Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, Without normaliation\n",
      "[[61122    92]\n",
      " [ 3983    19]]\n",
      "Confusion matrix normalization\n",
      "[[1. 0.]\n",
      " [1. 0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUQAAAEYCAYAAAAkpo9KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAm3UlEQVR4nO3debxVVf3/8deb0QEBB1AGcQATxcwcQM2BBhVH7JuzVk4ppfGrvmbmN4fUvlbmNys1HCqnFMVMEBEsywELQVBRQBMFGTVQhBwKuX5+f+x1ZXO9954D3HvPcN9PHufB2XuvvfY6+97zuWvYa29FBGZmBm1KXQAzs3LhgGhmljggmpklDohmZokDoplZ4oBoZpY4ILZCkh6VdGZ6f7Kkh5s4/20lhaR2TZlvgWNK0u8kLZM0eT3y2V/SS01ZtlKR1EfSO5LalroslcIBsRlImivpDUkb59adKenREharXhHx+4g4uNTlaAL7AQcBvSNi4LpmEhFPRMSOTVes5pF+x77QWJqImBcRnSKipqXKVekcEJtPO+D/rW8mqebjn1Nh2wBzI+LdUhekHLRk7bya+IvWfK4CzpPUtb6NkvaVNEXS8vT/vrltj0r6kaQngfeA7VMT9BuSXpb0L0mXS+or6e+SVki6R1KHtP+mksZKWpKakGMl9W6gHKdKmpjen5+aWLWvDyTdkrZ1kfQbSYslLZR0RW1TTFJbST+TtFTSq8DhjZ0YSVtLui+V701J16b1bST9QNJrkv4p6TZJXdK22mb4VyXNS8f6n7TtDOBmYJ9U7h/mP1fuuCGpX3p/mKSZ6VwulHReWj9Y0oLcPjuln8fbkmZIOiq37RZJ10l6MOXzlKS+DXzm2vKfJml++rkMk7SXpOkp/2tz6ftK+ks6P0sl/b72d0nS7UAf4IH0ec/P5X+GpHnAX3Lr2knaTNICSUemPDpJmi3pK439rFqdiPCriV/AXOALwH3AFWndmcCj6f1mwDLgy2Q1yRPT8uZp+6PAPGBA2t4eCGAM0Dmt/w/wCLA90AWYCXw17b858CVgI2ATYBRwf658jwJnpvenAhPr+QxbA4uAw9Ly/cANwMZAd2AycHbaNgx4Me2zGfDXVN529eTbFngO+HnKawNgv7TtdGB2+kyd0vm7PW3bNuV5E7Ah8Kl0Dnaq73PU97nS/v3S+8XA/un9psDu6f1gYEF63z6V50KgA/A54F/Ajmn7LcBbwMD0c/o9MLKB34na8o9In/lg4N/pvHYHegH/BA5M6fuRdQF0BLoBjwPX1P0dqyf/29J53TC3rl1KczDwejreTcC9pf6ulNur5AWoxherA+IuwPL0C50PiF8GJtfZ5+/Aqen9o8BldbYH8Jnc8lTge7nlq/NfmDr77gYsyy0/SiMBMX2ZPsof2DIFnw1zaU4E/pre/wUYltt2MA0HxH2AJQ1sewT4Rm55R+CDFGxqv9y9c9snAyfU9zka+Fz5gDgPOBvoXCfNYFYHxP1TAGmT234XcGl6fwtwc27bYcCLDfwMasvfK7fuTeD43PIfgG81sP/RwDN1f8fqyX/7eta1y637FfA82R+7zUv9XSm3l5vMzSgiXgDGAhfU2dQTeK3OutfIagm15teT5Ru59+/Xs9wJQNJGkm5ITc8VZLWLrip+tPE3wEsR8ZO0vA1ZbWlxatq9TVZb7J77PPny1v1seVsDr0XEqnq21T0vr5EFwy1z617PvX+P9JnXwZfIAthrkh6TtE8D5ZkfER/WKVP+57S25Sn2Z9hd0sjUnF8B3AFsUSBvqP/3Ju9Gsj/Uv4uIN4vIr1VxQGx+lwBfY80v0SKyIJPXB1iYW16f2xD9N1ntalBEdAYOSOtVaEdJF6R9z8itnk9WQ9wiIrqmV+eIGJC2LyYLdLX6NHKI+UAf1d/pX/e89AFWsWbQKNa7ZF0GAEjaKr8xIqZExFCyoH4/cE8D5dlaaw5q1f05NZcryX4Hdk0/w1NY8+fX0O9Hg7836Q/iDWTN6q/X9qfaag6IzSwiZgN3A8Nzq8cBn5B0UurwPh7Ymaw22RQ2IattvC1pM7KgXJCkQ1M5j46I93OfYTHwMHC1pM5p8KOvpANTknuA4ZJ6S9qUj9eI8yaTBdAfS9pY0gaSPpO23QV8W9J2kjoB/wvc3UBtspDngAGSdpO0AXBp7nN2UHb9ZZeI+ABYAdR3acpTZIH1fEntJQ0GjgRGrkN51tYmwDtkP8NewHfrbH+DrK91bVyY/j8d+Blw21q0GloFB8SWcRlZRzcAqalyBFlN7k3gfOCIiFjaRMe7hqwfcCkwCRhf5H7Hk/V3ztLqkeYRadtXyAYWZpINAN0L9EjbbgImkAWhaWSDIfWK7Jq4I8kGDeYBC9JxAX4L3E7WxJ9DNujwzSLLXvc4/yA7738GXgYm1knyZWBuao4OI6uB1c1jJXAUcCjZubwe+EpEvLguZVpLPwR2J+uDfpCPn9MrgR+kLozzCmUmaQ/gO2TlrwF+QlabbOyPV6uj1NFqZtbquYZoZpY4IJqZJQ6IZmaJA6KZWeIJ4OtA7TYMddik1MVodT69U2OXN1pzee21uSxdurTgNazFatt5m4hV7xdMF+8vmRARQ5rquMVwQFwH6rAJHXc8rtTFaHWefOrawomsyX1m0J5Nml+ser+o78+/n72umJk5TcoB0cxalgRtyvN6cAdEM2t5ZXqLTwdEM2t5arIuySblgGhmLcxNZjOzjHCT2cwsIzeZzcw+4iazmRlkNUQ3mc3Msj5E1xDNzMA1RDOzvDYeVDEzc5PZzGw1N5nNzFbzdYhmZvhuN2Zma3CT2cwscZPZzAx8txszs1q+242ZWS3XEM3MVnMN0cws8aCKmRm+DtHMLE+uIZqZpUFmB0QzM0BCvv2XmVnGNUQzs8QB0cwM0u0QHRDNzBByDdHMrFabNp6pYmYGuA/RzCyj9CpD5VlvNbOqJUSbNm0KvgrmIw2R9JKk2ZIuqGd7F0kPSHpO0gxJpxXK0wHRzFqcpIKvAvu3Ba4DDgV2Bk6UtHOdZOcAMyPiU8Bg4GpJHRrL1wHRzFqeing1biAwOyJejYiVwEhgaJ00AWyiLLp2At4CVjWWqfsQzaxlqehR5i0kPZ1bvjEibkzvewHzc9sWAIPq7H8tMAZYBGwCHB8RHzZ2QAdEM2txRY4yL42IPRvKop51UWf5EOBZ4HNAX+BPkp6IiBUNHdBN5iox4pKTee2RK3l61IUNprn6/GN4YfQlTL77++zWv/dH6w/adyee++NFvDD6Es477aCWKG7VeHjCeHYdsCMD+vfjqp/++GPbI4LvfGs4A/r3Y69P78oz06YVvW+1qr0we336EMlqhFvnlnuT1QTzTgPui8xsYA7Qv7FMHRCrxO0PTGLoOdc1uP2Q/Xamb59u7DL0h5x7xV388sITAGjTRlxzwXEMPfd6Pv2lKzh2yB70336rlip2RaupqeFbw89h9AMP8cz0mYwaeRezZs5cI82E8Q/xyuyXeWHWy1z76xsZfu7Xi963aqWpe4VeBUwBdpC0XRooOYGseZw3D/g8gKQtgR2BVxvL1AGxSjw57RXeWv5eg9uPOHBX7hw7GYDJz8+lyyYbstUWndlrl215Zf5S5i58kw9W1TBqwjSOGLxrSxW7ok2ZPJm+ffux3fbb06FDB449/gTGPjB6jTRjx4zmpFO+giQG7b03y5e/zeLFi4vat5qtbw0xIlYB5wITgFnAPRExQ9IwScNSssuBfSU9DzwCfC8iljaWr/sQW4me3buy4PVlHy0vfONtenbvSs/uXVjwRn79Mgbusm0JSlh5Fi1aSO/eq1ttvXr1ZvLkpwqmWbRwYVH7VrOmuLlDRIwDxtVZNyL3fhFw8Nrk6YCYSBoMrIyIv5W4KM2ivj+4EYHq6Zuu2zNt9Yv4+JmqW7NpKE0x+1azcv2sFREQJbWNiJpmPsxg4B2gKgPiwjfepvdWm3603GvLrixespwO7dvRe8v8+k1ZtGR5KYpYcXr16s2CBauv/Fi4cAE9e/YsmKZHz56sXLmy4L7VqshBk5Jotj5ESdtKmiXppjRt5mFJG0raTdIkSdMl/VHSpg3s/46kyyQ9Bewj6RRJkyU9K+mGdKV6bbqrJU2T9Iikbml9X0njJU2V9ISk/mn9kZKekvSMpD9L2lLStsAw4Nsp//2b67yUyoOPPc9JRwwEYOAnt2XFO+/z+tIVPD3jNfr16cY2PTenfbu2HHvI7jz46PQSl7Yy7LnXXsye/TJz58xh5cqVjLp7JIcfcdQaaQ4/8ijuvOM2IoKnJk2ic+cu9OjRo6h9q1lTTN1rDs1dQ9wBODEivibpHuBLwPnANyPiMUmXAZcA36pn342BFyLiYkk7Ad8DPhMRH0i6HjgZuC2lmxYR/y3p4pTfucCNwLCIeFnSIOB6suuRJgJ7R0RIOhM4P+07AngnIn5W3weRdBZwFgDtOzXBqWlat155KvvvsQNbdO3E7PGXc/mIcbRvlz3q8eZ7JzJ+4gwO2W8AM8Zcwnv//oCzL70DgJqaD/n2T+7hgevPoW0bcevoScx69fVSfpSK0a5dO37+i2s58vBDqKmp4aunns7OAwZw0w1ZN9bXzh7GkEMPY8JD4xjQvx8bbbgRN9z8u0b3bTXKs4KI6uvLaJKMs1rXnyJih7T8PWAD4IyI6JPW9QVGRcTu9ey/CugYETWSzgUuBP6ZNm8I3BURl0qqSelWSdoeuA/YD1gCvJTLsmNE7CTpk8DVQA+gAzAnIoZIupRGAmJem426R8cdj1vbU2LradmUa0tdhFbpM4P2ZOrUp5sshHXccofodfIvCqab8/PDpzZyYXazaO4a4n9y72uArvUlSs3fqWlxTERcDPw7128o4NaI+H4RxwyyroC3I2K3erb/Cvi/iBiTBlIuLSJPM2siUnb9azlq6Yb6cmBZro/uy8BjEVETEbul18X17PcIcIyk7gCSNpO0TdrWBjgmvT8JmJim5syRdGxKL0mfSmm6AAvT+6/mjvEvsvmOZtasmmSmSrMoRc/lV4GrJE0HdgMuK7RDRMwEfgA8nPb7E1mTF+BdYICkqWR9hLX5nQycIek5YAar74RxKTBK0hNA/iLNB4AvVuugilk5kQq/SqHZmswRMRfYJbec75vbu4j9O9VZvhu4u4G0FwEX1Vk3BxhST9rRwMemBETEPwBP0TBrbmXcZK6I6xDNrHoIB8RmU7cmaWblr0yvy678gGhmFcZNZjOzjPBcZjOzRK4hmpnVcg3RzAyyO2aXZzx0QDSzluXLbszMctxkNjNLyjQeOiCaWcsq57vdOCCaWQsr30cIOCCaWYsr03jogGhmLcxNZjOzjKfumZnluIZoZpa4hmhmBp66Z2ZWS5V4txtJvyJ7pGe9ImJ4s5TIzKpemyaoIkoaAvwCaAvcHBE/rifNYOAaoD2wNCIObCzPxmqIT69rQc3MGrO+8TA9y/064CBgATBF0pj0hM7aNF2B64EhETGv9jHGjWkwIEbErXUKsHFEvLuO5TczA7Jg2Hb9m8wDgdkR8WqWp0aSPWp4Zi7NScB9ETEPICL+WSjTgs9llrSPpJnArLT8KUnXr335zcwyTfCg+l7A/NzygrQu7xPAppIelTRV0lcKZVrMoMo1wCHAGICIeE7SAUXsZ2ZWryKbzFtIynfd3RgRN9ZmUU/6umMe7YA9gM8DGwJ/lzQpPYO9XkWNMkfE/DoRu6aY/czM6hLQtriIuDQi9mxg2wJg69xyb2BRPWmWpq6+dyU9DnwKaDAgFmwyA/Ml7QuEpA6SziM1n83M1loRzeUimsxTgB0kbSepA3ACqRWbMxrYX1I7SRsBgygQu4qpIQ4jG9ruBSwEJgDnFLGfmdnHiPUfVImIVZLOJYtHbYHfRsQMScPS9hERMUvSeGA68CHZpTkvNJZvwYAYEUuBk9er9GZmOU0xUyUixgHj6qwbUWf5KuCqYvMsZpR5e0kPSFoi6Z+SRkvavtgDmJnV1QRN5mZRTB/incA9QA+gJzAKuKs5C2Vm1av2OsRCr1IoJiAqIm6PiFXpdQeNTOkzMytERbxKobG5zJult3+VdAEwkiwQHg882AJlM7MqVYm3/5pKFgBrS352blsAlzdXocysekmlaxIX0thc5u1asiBm1nqUaQWxuJkqknYBdgY2qF0XEbc1V6HMrLpVYpMZAEmXAIPJAuI44FBgIuCAaGZrrSkuzG4uxYwyH0M2Ofr1iDiNbC5gx2YtlZlVtYobZc55PyI+lLRKUmfgn4AvzDazdSI1zR2zm0MxAfHpdOfZm8hGnt8BJjdnocysulXcM1VqRcQ30tsRaaJ054iY3rzFMrNqVqYVxEYvzN69sW0RMa15imRm1awir0MErm5kWwCfa+KymFkrUXGX3UTEZ1uyIGbWehRzeUsp+EH1Ztaiyvk6RAdEM2txZRoPHRDNrGVJ5duHWMwdsyXpFEkXp+U+kgY2f9HMrFq1bVP4VQrFHPZ6YB/gxLT8L+C6ZiuRmVU1kc1UKfQqhWKazIMiYndJzwBExLL02D8zs3VSyaPMH0hqS3psgKRuZI/0MzNba+V8YXYxgfqXwB+B7pJ+RHbrr/9t1lKZWVXLBlYaf5VCMXOZfy9pKtktwAQcHRGzmr1kZlaVBLQr0xpiMTeI7QO8BzyQXxcR85qzYGZWvcr0qpui+hAfZPXDpjYAtgNeAgY0Y7nMrFqpgi/MjohP5pfTXXDObiC5mVmjBLQt0yriWs9UiYhpkvZqjsKYWetQsTVESd/JLbYBdgeWNFuJzKzqVezUPWCT3KsjWZ/i0OYslJlVL6lppu5JGiLpJUmzJV3QSLq9JNVIOqZQno3WENMF2Z0i4ruFi2dmVpz1nZqXYtN1wEHAAmCKpDERMbOedD8BJhRVrkYO2C4iasiayGZmTSKby1z4VcBAYHZEvBoRK4GR1N9y/SbwB7KnhRbUWA1xMlkwfFbSGGAU8G7txoi4r5gDmJmtScWOMm8h6enc8o0RcWN63wuYn9u2ABi0xlGkXsAXyR53UtRAcDGjzJsBb6ZMa69HDMAB0czWmij6wuylEbFnI9nUFXWWrwG+FxE1xQ7iNBYQu6cR5hdYHQgbOrCZWXHUJFP3FgBb55Z7A4vqpNkTGJmC4RbAYZJWRcT9DWXaWEBsC3SiuEhsZlaUtaghNmYKsIOk7YCFwAnASfkEEbHdR8eUbgHGNhYMofGAuDgiLlvX0pqZNWR9R5kjYpWkc8lGj9sCv42IGZKGpe0j1iXfxgJieV45aWYVLZu6t/75RMQ4YFyddfUGwog4tZg8GwuIny+6ZGZmxSrjh0w19qD6t1qyIGbWepRnOPRjSM2shVXV3W7MzNZXmcZDB0Qza2mqvD5EM7Pm4CazmVlOeYZDB0Qza2GSa4hmZh9xH6KZWVKe4dAB0cxamAdVzMxyyjQeOiCaWUsTKtNGswOimbUoN5nNzGqpfJvMxTyX2SrAiEtO5rVHruTpURc2mObq84/hhdGXMPnu77Nb/94frT9o35147o8X8cLoSzjvtINaorhV4+EJ49l1wI4M6N+Pq376449tjwi+863hDOjfj70+vSvPTJtW9L7VTCr8KgUHxCpx+wOTGHrOdQ1uP2S/nenbpxu7DP0h515xF7+88AQA2rQR11xwHEPPvZ5Pf+kKjh2yB/2336qlil3Rampq+Nbwcxj9wEM8M30mo0bexayZazwWmAnjH+KV2S/zwqyXufbXNzL83K8XvW+1qm0yF3qVggNilXhy2iu8tfy9BrcfceCu3Dl2MgCTn59Ll002ZKstOrPXLtvyyvylzF34Jh+sqmHUhGkcMXjXlip2RZsyeTJ9+/Zju+23p0OHDhx7/AmMfWD0GmnGjhnNSad8BUkM2ntvli9/m8WLFxe1bzVTEf9KwQGxlejZvSsLXl/20fLCN96mZ/eu9OzehQVv5Ncvo1e3LqUoYsVZtGghvXuvfvBbr169WbhwYcE0ixYuLGrfalauTWYPqiSSjgb+ERFV2W6p7xcsIur9S+xHKhYn4uNnqu6UtIbSFLNvtfIo83pS9puiiPiwGQ9zNDAWqMqAuPCNt+m91aYfLffasiuLlyynQ/t29N4yv35TFi1ZXooiVpxevXqzYMH8j5YXLlxAz549C6bp0bMnK1euLLhv9Srf6xDLtsksaVtJsyRdD0wDLpI0RdJ0ST/MpXlR0q1p/b2SNkrb9pD0mKSpkiZI6pHWfy3l85ykP0jaSNK+wFHAVZKeldS3VJ+7uTz42POcdMRAAAZ+cltWvPM+ry9dwdMzXqNfn25s03Nz2rdry7GH7M6Dj04vcWkrw5577cXs2S8zd84cVq5cyai7R3L4EUetkebwI4/izjtuIyJ4atIkOnfuQo8ePYrat2oJ2hTxKoVyryHuCJwG3A8cAwwkq3GPkXQAMC+lOSMinpT0W+Abkn4B/AoYGhFLJB0P/Ag4HbgvIm4CkHRF2vdXksaQPcj63voKIuks4CwA2ndqrs+7zm698lT232MHtujaidnjL+fyEeNo364tADffO5HxE2dwyH4DmDHmEt779wecfekdANTUfMi3f3IPD1x/Dm3biFtHT2LWq6+X8qNUjHbt2vHzX1zLkYcfQk1NDV899XR2HjCAm27InoT5tbOHMeTQw5jw0DgG9O/HRhtuxA03/67RfVsDsf7PZW4uqq8voxxI2hb4a0RsJ+lnZAHx7bS5E3Al8AjweET0Sft8DhgO/AD4G/BqSt8WWBwRB0s6ELgC6JrymRARwyTdQiMBMa/NRt2j447HNcXHtLWwbMq1pS5Cq/SZQXsyderTTRbBdvrkp+N3f/xrwXT77LDp1IjYs6mOW4xyryG+m/4XcGVE3JDfmIJm3YgeKf2MiNinnjxvAY6OiOcknQoMbsLymlkRynUAqWz7EOuYAJwuqROApF6SuqdtfSTVBr4TgYnAS0C32vWS2kuqbY9sAiyW1B44OXeMf6VtZtbMyvWym4oIiBHxMHAn8HdJzwP3sjp4zQK+Kmk6sBnw64hYSdbE/omk54BngX1T+ouAp4A/AS/mDjMS+K6kZ6pxUMWsnKiIVymUbZM5IuYCu+SWfwH8Ip8mNZk/jIhh9ez/LHBAPet/Dfy6nvVPAjuvZ7HNrABRvk3msg2IZlalfLeb5hERcyNil8IpzaycNEWTWdIQSS9Jmi3pgnq2n5yuT54u6W+SPlUoT9cQzayFab2bzJLaAtcBBwELgCmSxtSZejsHODAilkk6FLgRGNRYvhVdQzSzytQEo8wDgdkR8WoaRB0JDM0niIi/RUTtnUsmAb0pwAHRzFpUNqhSVEDcQtLTuddZuWx6AfNzywvSuoacATxUqGxuMptZiyvy5g5LG5mpUl8G9U67k/RZsoC4X6EDOiCaWYtrglHmBcDWueXewKKPH0e7AjcDh0bEm4UydZPZzFpWEc3lIgLmFGAHSdtJ6gCcAIxZ4zBSH+A+4MsR8Y9iiuYaopm1uPW9H2JErJJ0Ltm03rbAbyNihqRhafsI4GJgc+D6NKq9qtDNIhwQzaxF1Q6qrK+IGAeMq7NuRO79mcCZa5OnA6KZtbhynanigGhmLa5cHyHggGhmLc41RDOzxAHRzIzamzeUZ0R0QDSzllXCp+oV4oBoZi3PAdHMDMr5QfUOiGbWorLnMpe6FPVzQDSzlueAaGaWcZPZzCxxk9nMDMr6qXsOiGZWAuUZER0QzaxFeZTZzCzHTWYzs8SjzGZmiWuIZmYU/RCpknBANLMWpzKNiA6IZtbiyjMcOiCaWQmUaQXRAdHMWpYQbco0IrYpdQHMzMqFa4hm1uLKtILogGhmLUyUbZPZAdHMWpTwKLOZ2WplGhEdEM2sxbnJbGaWlGc4dEA0sxIo16l7iohSl6HiSFoCvFbqcqyjLYClpS5EK1TJ532biOjWVJlJGk92PgpZGhFDmuq4xXBAbGUkPR0Re5a6HK2Nz3tl8EwVM7PEAdHMLHFAbH1uLHUBWimf9wrgPkQzs8Q1RDOzxAHRzCxxQDQzSxwQzcwSB0QriiRP82xiyvRI7/tIal/qMrV2/iW3eimbbLonsAjYBthM0kMRUVPaklWVvYB9JHUETgU+DywuaYlaOdcQrSGdgU8C1wEjgYURUaNynZVfgSJiMrA3cDFwXUQ4GJaYa4hWr4hYLmk2sB8wAXgnrfeFq03rFmAF0FvSAcCkiFgpqU1EfFjaorU+vjDb1iBJERG5/3cBDiO7O8mYiJgoaTPg3xHxXmlLW3ly53UvoC2wJCJekXQZsDkwIv2/LXCr/wC1LAdE+0juyzoEOAaYBYwDlgDfIutiWQF8Fjg9IhaWqqyVTNJRwA+Bh4G+wG3AWOBSYCvgKOCsiBhTqjK2Vg6ItgZJhwFXABcBXwF6ABeQBcfjgUOBWyLijyUrZAWTtCPwa+BEYCgwHHgBuDci7pW0NbBxRLxY+weqhMVtdRwQ7SOSNgG+C9wO7EBWYxlJVmP5n4h4UlLHiPiPv6zrRtK2ZANWmwLXAF8mq40fBdwQETeUrHDmgNja1Q1sKShuAdwBnA4sBP4MBHAk8JY7+4uX64bYCVgGEBGvS/oa2ffvRkknA/sCN0bEc6Usb2vnUeZWLPdlPRjoD3QA/g9oTxYIXwV2BZ4FromISr0Ffsmk81vbDfEH4HBJJwHvAjeni7GHk/XJOhiWmK9DbMXSl/VQ4EpgJlmN8KcR8RawATAKuB8YGxEvlqygFUzSdmRdD0PJBqQErIiIO8nOdzfg/0XEkyUrpH3ENUQ7AjgOGAC8BVwLEBFHSeoHtI2Il0pYvoqU64qoIRup3w04GTglIt6S9HlgdESMrJPeSsh9iK1YmnXyK7Km8vbANyLiH5KOA2oi4g8lLWAFynVDbBQR76U54I8BOwN9IuJfkvYnqzWeHhGV+vTGquSA2ApJGgC8R9bJvxPZF/aUiLhH0j7A74AzI2JiCYtZsdJ1nN8ku5zmObJLli4FXgaeAc4DLo2I0aUqo9XPAbGVyNVcBgO/ASYD3YGryJp1NwMPAYOAiyJibImKWtEk7UE2N/kuYDOyGzgsIrv28H+A+cDUiJjgZnL5cUBsRdJc2cPJBkueB/YHria708oKsj7ldhExw1/WtSepD/AocHdEfF/SxsAnyGqEF0TE/FKWzwrzKHMrIKltensh2RS8NyLiPxHxZ7Lm8eER8UpEvBQRM8A3cVgXETEPuBs4S1K/iHg3Ip4hG7HvW9rSWTE8ylzFcrW8jcku9RgiaTxwK/C5lGwlWS3G1lKdGzX0I+svvAJ4G7hf0nCy+xsOILvu0Mqca4hVLHejhpsl/UDSERExBNhI0kxJp5M1oT2avA7S+T2SrJa9I/B74KiI+AkwhuxymwuB4yJiiu8lWf4cEKuYpH3JZp78mGxq2MkAEbE3Wef+JcDXI2K0b1+/9iT1Bw4hq20/TvZ9eiRt/h/gfLI54UtKUkBbax5UqTK5ZtzGwJfILq15Hbge+FJEzJPUJd0AdgKwQUQcWMoyV5Lc+R1INnI8iayPcGfgxIiYm6bq/SMiZkv6EbAPMAT4wH2z5c0BsYrkvqxfIHseykzgp2T9hJ+PiCWpiTcoIn6Q9hlLdkH2vJIVvMKkYHgx8EuyO9f8ADgvIv6cruO8ley6zskp/eYR8WbJCmxFc5O5iqRguDcwGHiS7Nb/j5NdX9hR0iDgR2S1mtp9jnAwXGtdye4LuSNZP+HfgDMl/ZbsGs/v1AZDAAfDyuEaYpVIHfYCppHda2+nNHXsILKLrY8C3gRGpD5DX2e4HiQdTVb7Phf4E1mNfGtgTkQ84/NbmRwQq0zqO5wGPBkRp+fWdwU+jIgV/rI2DUlHAJcBP0t3r7EK54BYRXJ3s94YeIosKJ5d6nJVM0lDyW6f9gXgdd88t7I5IFYJSe0j4gNJvciegzIDmA08FBFnlrZ01U1St4jwpTVVwIMqFaj2Al9JPSV1lNQpBcPtgfuAHSPifbIZKLeXsqytgYNh9XANsUKlGSiXAC+STc37PrALsEtE/EhS24ioSWndZ2hWBAfECiTpE2RTw74GvEE2gvxF4Oja2oqDoNnac5O5QtSZB/sf4ImIeAKYHRE/IxtZPqw2rYOh2dpzQKwQ6aLrAyWdTXaX68MlnZYb1VwGbF6btlTlNKtkvv1XmctNxxtENh/5JbIpefcBP5LUnezW9EeR3evQzNaR+xArQJo7exlwfkRMl3QK2UOhtiJ7jOUsYLJv+2+2flxDrAxdyS78PQiYDowke3ToBmS1w2tSLdJ9h2brwQGxAkTEw5L+C7hS0qKIuEvS3Wnzs7VB0MHQbP04IFaIiBgjaRVwuaQOEXEr4PmzZk3IfYgVRtJRZHfA9txZsybmgFiBPHfWrHk4IJqZJb4w28wscUA0M0scEM3MEgdEM7PEAdEaJKlG0rOSXpA0StJG65HXLZKOSe9vlrRzI2kHS9p3HY4xV9IWxa6vk+adtTzWpZLOW9syWnlzQLTGvB8Ru0XELmTPdh6W3yip7bpkGhFnRsTMRpIMBtY6IJqtLwdEK9YTQL9Ue/urpDuB5yW1lXSVpCmSpqfbk6HMtZJmSnoQ6F6bkaRHJe2Z3g+RNE3Sc5IekbQtWeD9dqqd7i+pm6Q/pGNMkfSZtO/mkh6W9IykG8gew9ooSfdLmipphqSz6my7OpXlEUnd0rq+ksanfZ6Q1L9JzqaVJU/ds4IktSN7MPv4tGog2aMK5qSgsjwi9pLUEXhS0sPAp8ke5P5JYEuyW5b9tk6+3YCbgANSXptFxFuSRgDvpBvfkoLvzyNioqQ+wASye0JeAkyMiMskHQ6sEeAacHo6xobAFEl/SA+S3xiYFhH/LenilPe5wI3AsIh4OXcLts+tw2m0CuCAaI3ZUNKz6f0TwG/ImrKTI2JOWn8wsGtt/yDQBdgBOAC4Kz3XZZGkv9ST/97A47V5RcRbDZTjC8DOuZuGd5a0STrGf6V9H5S0rIjPNFzSF9P7rVNZ3wQ+BGpvmHEHcJ+kTunzjsodu2MRx7AK5YBojXk/InbLr0iB4d38KuCbETGhTrrDgELToFREGsi6dvZJTxKsW5aip1pJGkwWXPeJiPckPUp2C7X6RDru23XPgVUv9yHa+poAfF1Se8gegCVpY+Bx4ITUx9gD+Gw9+/4dOFDSdmnfzdL6fwGb5NI9TNZ8JaXbLb19HDg5rTsU2LRAWbsAy1Iw7E9WQ63VBqit5Z5E1hRfAcyRdGw6hiR9qsAxrII5INr6upmsf3CapBeAG8haHn8ku3nt88Cvgcfq7phuUHEWWfP0OVY3WR8Avlg7qAIMB/ZMgzYzWT3a/UPgAEnTyJru8wqUdTzQTtJ04HJgUm7bu8AASVPJ+ggvS+tPBs5I5ZsBDC3inFiF8s0dzMwS1xDNzBIHRDOzxAHRzCxxQDQzSxwQzcwSB0Qzs8QB0cws+f/OuHHlzIvG+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 混淆矩阵\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# label_name\n",
    "class_names = ['no-repeat', 'repeat']\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, random_state=0)\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "y_pred = clf.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix,\n",
    "    Normalization can be applied by setting 'normalize=True'\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print('Confusion matrix normalization')\n",
    "    else:\n",
    "        print('Confusion matrix, Without normaliation')\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j,\n",
    "                 i,\n",
    "                 format(cm[i, j], fmt),\n",
    "                 horizontalalignment='center',\n",
    "                 color='white' if cm[i, j] > thresh else 'black')\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.tight_layout()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix,\n",
    "                      classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix,\n",
    "                      classes=class_names,\n",
    "                      normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T05:58:57.840285Z",
     "start_time": "2021-07-12T05:58:48.357695Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9386193572129539"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逻辑回归模型\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T05:59:04.301565Z",
     "start_time": "2021-07-12T05:59:01.110413Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9386193572129539"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN 模型\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T05:59:08.619090Z",
     "start_time": "2021-07-12T05:59:04.303588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7291615554465162"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 高斯贝叶斯模型\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T06:00:05.736408Z",
     "start_time": "2021-07-12T05:59:08.620110Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8820074828263003"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 决策树模型\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T06:19:48.831975Z",
     "start_time": "2021-07-12T06:00:05.737416Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9386346908734053"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bagging模型\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = BaggingClassifier(base_estimator=KNeighborsClassifier(), max_samples=0.5, max_features=0.5).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T06:20:11.004279Z",
     "start_time": "2021-07-12T06:19:48.833976Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9365799803729146"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机森林模型\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T06:20:33.491411Z",
     "start_time": "2021-07-12T06:20:11.006289Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9365799803729146"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 极端森林模型\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T06:23:39.969628Z",
     "start_time": "2021-07-12T06:20:33.493404Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.938588689892051"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoost模型\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T06:33:18.117583Z",
     "start_time": "2021-07-12T06:23:39.971628Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9075226938174681"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GBDT模型\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, target, random_state=0)\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T07:13:06.898691Z",
     "start_time": "2021-07-12T06:38:45.952908Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94 (+/-0.00) [Logistic Regression]\n",
      "Accuracy: 0.94 (+/-0.00) [Random Forest]\n",
      "Accuracy: 0.73 (+/-0.00) [naive Bayes]\n",
      "Accuracy: 0.94 (+/-0.00) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# 集成学习\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "X = stdScaler.fit_transform(train)\n",
    "y = target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial', random_state=0)\n",
    "clf2 = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf],\n",
    "                      ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X,y, cv=5, scoring='accuracy')\n",
    "    print('Accuracy: %0.2f (+/-%0.2f) [%s]' % (scores.mean(), scores.std(), label) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T09:32:03.004360Z",
     "start_time": "2021-07-12T09:31:54.695142Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: collsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: collsample_bytree\n",
      "[LightGBM] [Warning] Unknown parameter: learn_rate\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: collsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: collsample_bytree\n",
      "[LightGBM] [Warning] Unknown parameter: learn_rate\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 30916\n",
      "[LightGBM] [Info] Number of data points in the train set: 156518, number of used features: 129\n",
      "[LightGBM] [Warning] Unknown parameter: collsample_bylevel\n",
      "[LightGBM] [Warning] Unknown parameter: collsample_bytree\n",
      "[LightGBM] [Warning] Unknown parameter: learn_rate\n",
      "[LightGBM] [Warning] Unknown parameter: tree_method\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score -0.063045\n",
      "[LightGBM] [Info] Start training from score -2.795270\n",
      "[1]\tvalid_0's multi_logloss: 0.227685\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.226753\n",
      "[3]\tvalid_0's multi_logloss: 0.226017\n",
      "[4]\tvalid_0's multi_logloss: 0.225492\n",
      "[5]\tvalid_0's multi_logloss: 0.225046\n",
      "[6]\tvalid_0's multi_logloss: 0.22465\n",
      "[7]\tvalid_0's multi_logloss: 0.224345\n",
      "[8]\tvalid_0's multi_logloss: 0.224115\n",
      "[9]\tvalid_0's multi_logloss: 0.223957\n",
      "[10]\tvalid_0's multi_logloss: 0.223798\n",
      "[11]\tvalid_0's multi_logloss: 0.223677\n",
      "[12]\tvalid_0's multi_logloss: 0.223605\n",
      "[13]\tvalid_0's multi_logloss: 0.223494\n",
      "[14]\tvalid_0's multi_logloss: 0.223426\n",
      "[15]\tvalid_0's multi_logloss: 0.223421\n",
      "[16]\tvalid_0's multi_logloss: 0.223418\n",
      "[17]\tvalid_0's multi_logloss: 0.223382\n",
      "[18]\tvalid_0's multi_logloss: 0.223342\n",
      "[19]\tvalid_0's multi_logloss: 0.223302\n",
      "[20]\tvalid_0's multi_logloss: 0.223286\n",
      "[21]\tvalid_0's multi_logloss: 0.223288\n",
      "[22]\tvalid_0's multi_logloss: 0.223266\n",
      "[23]\tvalid_0's multi_logloss: 0.223263\n",
      "[24]\tvalid_0's multi_logloss: 0.22327\n",
      "[25]\tvalid_0's multi_logloss: 0.223297\n",
      "[26]\tvalid_0's multi_logloss: 0.223324\n",
      "[27]\tvalid_0's multi_logloss: 0.223341\n",
      "[28]\tvalid_0's multi_logloss: 0.223353\n",
      "[29]\tvalid_0's multi_logloss: 0.223396\n",
      "[30]\tvalid_0's multi_logloss: 0.223419\n",
      "[31]\tvalid_0's multi_logloss: 0.223391\n",
      "[32]\tvalid_0's multi_logloss: 0.223411\n",
      "[33]\tvalid_0's multi_logloss: 0.223429\n",
      "[34]\tvalid_0's multi_logloss: 0.22347\n",
      "[35]\tvalid_0's multi_logloss: 0.223489\n",
      "[36]\tvalid_0's multi_logloss: 0.223515\n",
      "[37]\tvalid_0's multi_logloss: 0.223521\n",
      "[38]\tvalid_0's multi_logloss: 0.223544\n",
      "[39]\tvalid_0's multi_logloss: 0.223566\n",
      "[40]\tvalid_0's multi_logloss: 0.223591\n",
      "[41]\tvalid_0's multi_logloss: 0.223582\n",
      "[42]\tvalid_0's multi_logloss: 0.2236\n",
      "[43]\tvalid_0's multi_logloss: 0.223633\n",
      "[44]\tvalid_0's multi_logloss: 0.223637\n",
      "[45]\tvalid_0's multi_logloss: 0.223667\n",
      "[46]\tvalid_0's multi_logloss: 0.223661\n",
      "[47]\tvalid_0's multi_logloss: 0.223686\n",
      "[48]\tvalid_0's multi_logloss: 0.223693\n",
      "[49]\tvalid_0's multi_logloss: 0.223686\n",
      "[50]\tvalid_0's multi_logloss: 0.223688\n",
      "[51]\tvalid_0's multi_logloss: 0.223697\n",
      "[52]\tvalid_0's multi_logloss: 0.223715\n",
      "[53]\tvalid_0's multi_logloss: 0.223718\n",
      "[54]\tvalid_0's multi_logloss: 0.223734\n",
      "[55]\tvalid_0's multi_logloss: 0.223744\n",
      "[56]\tvalid_0's multi_logloss: 0.223766\n",
      "[57]\tvalid_0's multi_logloss: 0.223808\n",
      "[58]\tvalid_0's multi_logloss: 0.223836\n",
      "[59]\tvalid_0's multi_logloss: 0.223851\n",
      "[60]\tvalid_0's multi_logloss: 0.223856\n",
      "[61]\tvalid_0's multi_logloss: 0.223852\n",
      "[62]\tvalid_0's multi_logloss: 0.223834\n",
      "[63]\tvalid_0's multi_logloss: 0.223835\n",
      "[64]\tvalid_0's multi_logloss: 0.223842\n",
      "[65]\tvalid_0's multi_logloss: 0.223854\n",
      "[66]\tvalid_0's multi_logloss: 0.22389\n",
      "[67]\tvalid_0's multi_logloss: 0.223897\n",
      "[68]\tvalid_0's multi_logloss: 0.223911\n",
      "[69]\tvalid_0's multi_logloss: 0.223929\n",
      "[70]\tvalid_0's multi_logloss: 0.223951\n",
      "[71]\tvalid_0's multi_logloss: 0.223972\n",
      "[72]\tvalid_0's multi_logloss: 0.223986\n",
      "[73]\tvalid_0's multi_logloss: 0.224024\n",
      "[74]\tvalid_0's multi_logloss: 0.224029\n",
      "[75]\tvalid_0's multi_logloss: 0.224034\n",
      "[76]\tvalid_0's multi_logloss: 0.224042\n",
      "[77]\tvalid_0's multi_logloss: 0.224041\n",
      "[78]\tvalid_0's multi_logloss: 0.224064\n",
      "[79]\tvalid_0's multi_logloss: 0.224076\n",
      "[80]\tvalid_0's multi_logloss: 0.224101\n",
      "[81]\tvalid_0's multi_logloss: 0.224087\n",
      "[82]\tvalid_0's multi_logloss: 0.224087\n",
      "[83]\tvalid_0's multi_logloss: 0.224105\n",
      "[84]\tvalid_0's multi_logloss: 0.22412\n",
      "[85]\tvalid_0's multi_logloss: 0.224145\n",
      "[86]\tvalid_0's multi_logloss: 0.224173\n",
      "[87]\tvalid_0's multi_logloss: 0.224168\n",
      "[88]\tvalid_0's multi_logloss: 0.224214\n",
      "[89]\tvalid_0's multi_logloss: 0.224221\n",
      "[90]\tvalid_0's multi_logloss: 0.224259\n",
      "[91]\tvalid_0's multi_logloss: 0.224253\n",
      "[92]\tvalid_0's multi_logloss: 0.224258\n",
      "[93]\tvalid_0's multi_logloss: 0.224249\n",
      "[94]\tvalid_0's multi_logloss: 0.224252\n",
      "[95]\tvalid_0's multi_logloss: 0.224271\n",
      "[96]\tvalid_0's multi_logloss: 0.224287\n",
      "[97]\tvalid_0's multi_logloss: 0.224288\n",
      "[98]\tvalid_0's multi_logloss: 0.224293\n",
      "[99]\tvalid_0's multi_logloss: 0.224298\n",
      "[100]\tvalid_0's multi_logloss: 0.224312\n",
      "[101]\tvalid_0's multi_logloss: 0.224319\n",
      "[102]\tvalid_0's multi_logloss: 0.224337\n",
      "[103]\tvalid_0's multi_logloss: 0.22436\n",
      "[104]\tvalid_0's multi_logloss: 0.22436\n",
      "[105]\tvalid_0's multi_logloss: 0.224362\n",
      "[106]\tvalid_0's multi_logloss: 0.224336\n",
      "[107]\tvalid_0's multi_logloss: 0.224345\n",
      "[108]\tvalid_0's multi_logloss: 0.224371\n",
      "[109]\tvalid_0's multi_logloss: 0.224379\n",
      "[110]\tvalid_0's multi_logloss: 0.224388\n",
      "[111]\tvalid_0's multi_logloss: 0.224408\n",
      "[112]\tvalid_0's multi_logloss: 0.224428\n",
      "[113]\tvalid_0's multi_logloss: 0.224456\n",
      "[114]\tvalid_0's multi_logloss: 0.224481\n",
      "[115]\tvalid_0's multi_logloss: 0.224489\n",
      "[116]\tvalid_0's multi_logloss: 0.224466\n",
      "[117]\tvalid_0's multi_logloss: 0.224473\n",
      "[118]\tvalid_0's multi_logloss: 0.224502\n",
      "[119]\tvalid_0's multi_logloss: 0.224509\n",
      "[120]\tvalid_0's multi_logloss: 0.224529\n",
      "[121]\tvalid_0's multi_logloss: 0.224534\n",
      "[122]\tvalid_0's multi_logloss: 0.22454\n",
      "[123]\tvalid_0's multi_logloss: 0.224558\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's multi_logloss: 0.223263\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "import lightgbm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(train)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target,\n",
    "                                                    test_size=0.4, random_state=0)\n",
    "\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test,\n",
    "                                                    test_size=0.5, random_state=0)\n",
    "\n",
    "clf = lightgbm\n",
    "train_matrix = clf.Dataset(X_train, label=y_train)\n",
    "test_matrix = clf.Dataset(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_logloss',\n",
    "    'min_child_weight': 1.5,\n",
    "    'num_leaves': 2**5,\n",
    "    'lambda_l2': 10,\n",
    "    'subsample': 0.7,\n",
    "    'collsample_bytree': 0.7,\n",
    "    'collsample_bylevel': 0.7,\n",
    "    'learn_rate': 0.03,\n",
    "    'tree_method': 'exact',\n",
    "    'seed': 2021,\n",
    "    'num_class': 2,\n",
    "    'silent': True\n",
    "}\n",
    "\n",
    "num_round = 10000\n",
    "early_stopping_rounds = 100\n",
    "model = clf.train(params,\n",
    "                  train_matrix,\n",
    "                  num_round,\n",
    "                  valid_sets=test_matrix,\n",
    "                  early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "pre = model.predict(X_valid, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T08:50:22.842958Z",
     "start_time": "2021-07-12T08:49:50.059064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:0.49575\teval-mlogloss:0.49549\n",
      "Multiple eval metrics have been passed: 'eval-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mlogloss hasn't improved in 100 rounds.\n",
      "[1]\ttrain-mlogloss:0.38952\teval-mlogloss:0.38916\n",
      "[2]\ttrain-mlogloss:0.32619\teval-mlogloss:0.32579\n",
      "[3]\ttrain-mlogloss:0.28690\teval-mlogloss:0.28648\n",
      "[4]\ttrain-mlogloss:0.26209\teval-mlogloss:0.26167\n",
      "[5]\ttrain-mlogloss:0.24653\teval-mlogloss:0.24617\n",
      "[6]\ttrain-mlogloss:0.23682\teval-mlogloss:0.23659\n",
      "[7]\ttrain-mlogloss:0.23104\teval-mlogloss:0.23094\n",
      "[8]\ttrain-mlogloss:0.22736\teval-mlogloss:0.22748\n",
      "[9]\ttrain-mlogloss:0.22524\teval-mlogloss:0.22562\n",
      "[10]\ttrain-mlogloss:0.22389\teval-mlogloss:0.22460\n",
      "[11]\ttrain-mlogloss:0.22305\teval-mlogloss:0.22401\n",
      "[12]\ttrain-mlogloss:0.22248\teval-mlogloss:0.22365\n",
      "[13]\ttrain-mlogloss:0.22202\teval-mlogloss:0.22349\n",
      "[14]\ttrain-mlogloss:0.22163\teval-mlogloss:0.22346\n",
      "[15]\ttrain-mlogloss:0.22138\teval-mlogloss:0.22346\n",
      "[16]\ttrain-mlogloss:0.22113\teval-mlogloss:0.22352\n",
      "[17]\ttrain-mlogloss:0.22092\teval-mlogloss:0.22361\n",
      "[18]\ttrain-mlogloss:0.22073\teval-mlogloss:0.22360\n",
      "[19]\ttrain-mlogloss:0.22055\teval-mlogloss:0.22362\n",
      "[20]\ttrain-mlogloss:0.22038\teval-mlogloss:0.22365\n",
      "[21]\ttrain-mlogloss:0.22020\teval-mlogloss:0.22367\n",
      "[22]\ttrain-mlogloss:0.21997\teval-mlogloss:0.22374\n",
      "[23]\ttrain-mlogloss:0.21966\teval-mlogloss:0.22373\n",
      "[24]\ttrain-mlogloss:0.21949\teval-mlogloss:0.22376\n",
      "[25]\ttrain-mlogloss:0.21922\teval-mlogloss:0.22380\n",
      "[26]\ttrain-mlogloss:0.21906\teval-mlogloss:0.22388\n",
      "[27]\ttrain-mlogloss:0.21893\teval-mlogloss:0.22389\n",
      "[28]\ttrain-mlogloss:0.21871\teval-mlogloss:0.22395\n",
      "[29]\ttrain-mlogloss:0.21851\teval-mlogloss:0.22400\n",
      "[30]\ttrain-mlogloss:0.21827\teval-mlogloss:0.22407\n",
      "[31]\ttrain-mlogloss:0.21814\teval-mlogloss:0.22413\n",
      "[32]\ttrain-mlogloss:0.21793\teval-mlogloss:0.22421\n",
      "[33]\ttrain-mlogloss:0.21778\teval-mlogloss:0.22427\n",
      "[34]\ttrain-mlogloss:0.21758\teval-mlogloss:0.22431\n",
      "[35]\ttrain-mlogloss:0.21746\teval-mlogloss:0.22437\n",
      "[36]\ttrain-mlogloss:0.21725\teval-mlogloss:0.22443\n",
      "[37]\ttrain-mlogloss:0.21705\teval-mlogloss:0.22449\n",
      "[38]\ttrain-mlogloss:0.21690\teval-mlogloss:0.22451\n",
      "[39]\ttrain-mlogloss:0.21671\teval-mlogloss:0.22454\n",
      "[40]\ttrain-mlogloss:0.21649\teval-mlogloss:0.22459\n",
      "[41]\ttrain-mlogloss:0.21629\teval-mlogloss:0.22460\n",
      "[42]\ttrain-mlogloss:0.21607\teval-mlogloss:0.22468\n",
      "[43]\ttrain-mlogloss:0.21590\teval-mlogloss:0.22473\n",
      "[44]\ttrain-mlogloss:0.21574\teval-mlogloss:0.22479\n",
      "[45]\ttrain-mlogloss:0.21552\teval-mlogloss:0.22482\n",
      "[46]\ttrain-mlogloss:0.21534\teval-mlogloss:0.22487\n",
      "[47]\ttrain-mlogloss:0.21519\teval-mlogloss:0.22490\n",
      "[48]\ttrain-mlogloss:0.21506\teval-mlogloss:0.22490\n",
      "[49]\ttrain-mlogloss:0.21493\teval-mlogloss:0.22495\n",
      "[50]\ttrain-mlogloss:0.21475\teval-mlogloss:0.22500\n",
      "[51]\ttrain-mlogloss:0.21441\teval-mlogloss:0.22501\n",
      "[52]\ttrain-mlogloss:0.21424\teval-mlogloss:0.22498\n",
      "[53]\ttrain-mlogloss:0.21409\teval-mlogloss:0.22505\n",
      "[54]\ttrain-mlogloss:0.21393\teval-mlogloss:0.22507\n",
      "[55]\ttrain-mlogloss:0.21369\teval-mlogloss:0.22509\n",
      "[56]\ttrain-mlogloss:0.21336\teval-mlogloss:0.22506\n",
      "[57]\ttrain-mlogloss:0.21325\teval-mlogloss:0.22507\n",
      "[58]\ttrain-mlogloss:0.21307\teval-mlogloss:0.22510\n",
      "[59]\ttrain-mlogloss:0.21290\teval-mlogloss:0.22514\n",
      "[60]\ttrain-mlogloss:0.21273\teval-mlogloss:0.22521\n",
      "[61]\ttrain-mlogloss:0.21260\teval-mlogloss:0.22522\n",
      "[62]\ttrain-mlogloss:0.21242\teval-mlogloss:0.22521\n",
      "[63]\ttrain-mlogloss:0.21227\teval-mlogloss:0.22519\n",
      "[64]\ttrain-mlogloss:0.21213\teval-mlogloss:0.22525\n",
      "[65]\ttrain-mlogloss:0.21201\teval-mlogloss:0.22529\n",
      "[66]\ttrain-mlogloss:0.21177\teval-mlogloss:0.22529\n",
      "[67]\ttrain-mlogloss:0.21162\teval-mlogloss:0.22531\n",
      "[68]\ttrain-mlogloss:0.21140\teval-mlogloss:0.22539\n",
      "[69]\ttrain-mlogloss:0.21129\teval-mlogloss:0.22543\n",
      "[70]\ttrain-mlogloss:0.21113\teval-mlogloss:0.22547\n",
      "[71]\ttrain-mlogloss:0.21097\teval-mlogloss:0.22550\n",
      "[72]\ttrain-mlogloss:0.21080\teval-mlogloss:0.22552\n",
      "[73]\ttrain-mlogloss:0.21066\teval-mlogloss:0.22554\n",
      "[74]\ttrain-mlogloss:0.21041\teval-mlogloss:0.22557\n",
      "[75]\ttrain-mlogloss:0.21026\teval-mlogloss:0.22560\n",
      "[76]\ttrain-mlogloss:0.21008\teval-mlogloss:0.22558\n",
      "[77]\ttrain-mlogloss:0.20997\teval-mlogloss:0.22559\n",
      "[78]\ttrain-mlogloss:0.20977\teval-mlogloss:0.22566\n",
      "[79]\ttrain-mlogloss:0.20962\teval-mlogloss:0.22570\n",
      "[80]\ttrain-mlogloss:0.20947\teval-mlogloss:0.22572\n",
      "[81]\ttrain-mlogloss:0.20938\teval-mlogloss:0.22579\n",
      "[82]\ttrain-mlogloss:0.20919\teval-mlogloss:0.22582\n",
      "[83]\ttrain-mlogloss:0.20902\teval-mlogloss:0.22586\n",
      "[84]\ttrain-mlogloss:0.20893\teval-mlogloss:0.22588\n",
      "[85]\ttrain-mlogloss:0.20872\teval-mlogloss:0.22591\n",
      "[86]\ttrain-mlogloss:0.20853\teval-mlogloss:0.22596\n",
      "[87]\ttrain-mlogloss:0.20835\teval-mlogloss:0.22601\n",
      "[88]\ttrain-mlogloss:0.20818\teval-mlogloss:0.22600\n",
      "[89]\ttrain-mlogloss:0.20795\teval-mlogloss:0.22600\n",
      "[90]\ttrain-mlogloss:0.20778\teval-mlogloss:0.22598\n",
      "[91]\ttrain-mlogloss:0.20754\teval-mlogloss:0.22598\n",
      "[92]\ttrain-mlogloss:0.20733\teval-mlogloss:0.22603\n",
      "[93]\ttrain-mlogloss:0.20714\teval-mlogloss:0.22607\n",
      "[94]\ttrain-mlogloss:0.20699\teval-mlogloss:0.22608\n",
      "[95]\ttrain-mlogloss:0.20681\teval-mlogloss:0.22610\n",
      "[96]\ttrain-mlogloss:0.20663\teval-mlogloss:0.22615\n",
      "[97]\ttrain-mlogloss:0.20644\teval-mlogloss:0.22617\n",
      "[98]\ttrain-mlogloss:0.20629\teval-mlogloss:0.22615\n",
      "[99]\ttrain-mlogloss:0.20615\teval-mlogloss:0.22619\n",
      "[100]\ttrain-mlogloss:0.20591\teval-mlogloss:0.22618\n",
      "[101]\ttrain-mlogloss:0.20569\teval-mlogloss:0.22626\n",
      "[102]\ttrain-mlogloss:0.20558\teval-mlogloss:0.22629\n",
      "[103]\ttrain-mlogloss:0.20545\teval-mlogloss:0.22629\n",
      "[104]\ttrain-mlogloss:0.20536\teval-mlogloss:0.22633\n",
      "[105]\ttrain-mlogloss:0.20522\teval-mlogloss:0.22633\n",
      "[106]\ttrain-mlogloss:0.20509\teval-mlogloss:0.22636\n",
      "[107]\ttrain-mlogloss:0.20490\teval-mlogloss:0.22638\n",
      "[108]\ttrain-mlogloss:0.20475\teval-mlogloss:0.22645\n",
      "[109]\ttrain-mlogloss:0.20458\teval-mlogloss:0.22648\n",
      "[110]\ttrain-mlogloss:0.20433\teval-mlogloss:0.22648\n",
      "[111]\ttrain-mlogloss:0.20421\teval-mlogloss:0.22648\n",
      "[112]\ttrain-mlogloss:0.20405\teval-mlogloss:0.22652\n",
      "[113]\ttrain-mlogloss:0.20384\teval-mlogloss:0.22655\n",
      "[114]\ttrain-mlogloss:0.20363\teval-mlogloss:0.22658\n",
      "[115]\ttrain-mlogloss:0.20347\teval-mlogloss:0.22663\n",
      "Stopping. Best iteration:\n",
      "[15]\ttrain-mlogloss:0.22138\teval-mlogloss:0.22346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGB\n",
    "import xgboost\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(train)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target,\n",
    "                                                    test_size=0.4, random_state=0)\n",
    "\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test, y_test,\n",
    "                                                    test_size=0.5, random_state=0)\n",
    "\n",
    "clf = xgboost\n",
    "train_matrix = clf.DMatrix(X_train, label=y_train, missing=-1)\n",
    "test_matrix = clf.DMatrix(X_test, label=y_test, missing=-1)\n",
    "z = clf.DMatrix(X_valid, label=y_valid, missing=-1)\n",
    "\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'multi:softprob',\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'gamma': 1,\n",
    "    'min_child_weight': 1.5,\n",
    "    'max_depth': 5,\n",
    "    'lambda': 10,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'colsample_bylevel': 0.7,\n",
    "    'tree_method': 'exact',\n",
    "    'seed': 2021,\n",
    "    'num_class': 2\n",
    "}\n",
    "\n",
    "num_round = 10000\n",
    "early_stopping_rounds=100\n",
    "watchlist = [(train_matrix, 'train'), (test_matrix, 'eval')]\n",
    "\n",
    "model = clf.train(params,\n",
    "                  train_matrix,\n",
    "                  num_boost_round=num_round,\n",
    "                  evals=watchlist,\n",
    "                  early_stopping_rounds=early_stopping_rounds)\n",
    "pre = model.predict(z, ntree_limit=model.best_ntree_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T09:33:36.004526Z",
     "start_time": "2021-07-12T09:33:35.980537Z"
    }
   },
   "outputs": [],
   "source": [
    "# 封装自己的模型\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "\n",
    "class SBBTree():\n",
    "    \"\"\"\n",
    "    SBBTree\n",
    "    Stacking Bootstrap bagging\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, stacking_num, bagging_num, bagging_test_size, num_boost_round, early_stopping_rounds):\n",
    "        \"\"\"\n",
    "        Initialize the SBBTree\n",
    "        :param params: lgm params\n",
    "        :param stacking_num: k_folds num\n",
    "        :param bagging_num: bootstrap num\n",
    "        :param bagging_test_size: bootstrap sample rate\n",
    "        :param num_boost_round: boost num\n",
    "        :param early_stopping_rounds: early_stopping_rounds\n",
    "        \"\"\"\n",
    "        self.params = params\n",
    "        self.stacking_num =  stacking_num\n",
    "        self.bagging_num = bagging_num\n",
    "        self.bagging_test_size = bagging_test_size\n",
    "        self.num_boost_round = num_boost_round\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "\n",
    "        self.model = lgb\n",
    "        self.stack_model = []\n",
    "        self.bagging_model = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" fit model.\"\"\"\n",
    "        if self.stacking_num > 1:\n",
    "            layer_train = np.zeros((X.shape[0], 2))\n",
    "            self.SK = StratifiedKFold(n_splits=self.stacking_num,\n",
    "                                      shuffle=True,\n",
    "                                      random_state=1)\n",
    "            for k, (train_index, test_index) in enumerate(self.SK.split(X,  y)):\n",
    "                X_train = X[train_index]\n",
    "                X_test = X[test_index]\n",
    "                y_train = y[train_index]\n",
    "                y_test = y[test_index]\n",
    "                lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "                lgb_eval = lgb.Dataset(X_test, label=y_test, reference=lgb_train)\n",
    "\n",
    "                gbm = lgb.train(params=self.params, train_set=lgb_train, num_boost_round=self.num_boost_round,\n",
    "                                valid_sets=lgb_eval, early_stopping_rounds=self.early_stopping_rounds)\n",
    "                self.stack_model.append(gbm)\n",
    "                pred_y = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "                layer_train[test_index, 1] = pred_y\n",
    "            X = np.hstack((X, layer_train[:, 1].reshape((-1, 1))))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        for bn in range(self.bagging_num):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.bagging_test_size, random_state=bn)\n",
    "            lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "            lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "            gbm = lgb.train(self.params,\n",
    "                            lgb_train,\n",
    "                            num_boost_round=10000,\n",
    "                            valid_sets=lgb_eval,\n",
    "                            early_stopping_rounds=200)\n",
    "            self.bagging_model.append(gbm)\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X_pred):\n",
    "        \"\"\" predict test data.\"\"\"\n",
    "        if self.stacking_num > 1:\n",
    "            test_pred = np.zeros((X_pred.shape[0], self.stacking_num))\n",
    "            for sn, gbm in enumerate(self.stack_model):\n",
    "                pred = gbm.predict(X_pred, num_iteration=gbm.best_iteration)\n",
    "                test_pred[:, sn] = pred\n",
    "                X_pred = np.hstack((X_pred, test_pred.mean(axis=1).reshape((-1, 1))))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        for bn, gbm in enumerate(self.bagging_model):\n",
    "            pred = gbm.predict(X_pred, num_iteration=gbm.best_iteration)\n",
    "            if bn == 0:\n",
    "                pred_out = pred\n",
    "            else:\n",
    "                pred_out += pred\n",
    "        return pred_out / self.bagging_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T09:33:41.522817Z",
     "start_time": "2021-07-12T09:33:40.525412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[1]\tvalid_0's auc: 0.962106\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[2]\tvalid_0's auc: 0.965848\n",
      "[3]\tvalid_0's auc: 0.977285\n",
      "[4]\tvalid_0's auc: 0.982713\n",
      "[5]\tvalid_0's auc: 0.983662\n",
      "[6]\tvalid_0's auc: 0.985111\n",
      "[7]\tvalid_0's auc: 0.985533\n",
      "[8]\tvalid_0's auc: 0.98606\n",
      "[9]\tvalid_0's auc: 0.985717\n",
      "[10]\tvalid_0's auc: 0.985164\n",
      "[11]\tvalid_0's auc: 0.988063\n",
      "[12]\tvalid_0's auc: 0.988827\n",
      "[13]\tvalid_0's auc: 0.98888\n",
      "[14]\tvalid_0's auc: 0.988827\n",
      "[15]\tvalid_0's auc: 0.988563\n",
      "[16]\tvalid_0's auc: 0.988774\n",
      "[17]\tvalid_0's auc: 0.98909\n",
      "[18]\tvalid_0's auc: 0.989775\n",
      "[19]\tvalid_0's auc: 0.989881\n",
      "[20]\tvalid_0's auc: 0.990303\n",
      "[21]\tvalid_0's auc: 0.990513\n",
      "[22]\tvalid_0's auc: 0.990724\n",
      "[23]\tvalid_0's auc: 0.990461\n",
      "[24]\tvalid_0's auc: 0.990671\n",
      "[25]\tvalid_0's auc: 0.990303\n",
      "[26]\tvalid_0's auc: 0.990197\n",
      "[27]\tvalid_0's auc: 0.990197\n",
      "[28]\tvalid_0's auc: 0.990355\n",
      "[29]\tvalid_0's auc: 0.990355\n",
      "[30]\tvalid_0's auc: 0.990092\n",
      "[31]\tvalid_0's auc: 0.99083\n",
      "[32]\tvalid_0's auc: 0.990724\n",
      "[33]\tvalid_0's auc: 0.990935\n",
      "[34]\tvalid_0's auc: 0.990882\n",
      "[35]\tvalid_0's auc: 0.990988\n",
      "[36]\tvalid_0's auc: 0.991093\n",
      "[37]\tvalid_0's auc: 0.991357\n",
      "[38]\tvalid_0's auc: 0.991146\n",
      "[39]\tvalid_0's auc: 0.991198\n",
      "[40]\tvalid_0's auc: 0.991673\n",
      "[41]\tvalid_0's auc: 0.991409\n",
      "[42]\tvalid_0's auc: 0.991304\n",
      "[43]\tvalid_0's auc: 0.991251\n",
      "[44]\tvalid_0's auc: 0.991304\n",
      "[45]\tvalid_0's auc: 0.991251\n",
      "[46]\tvalid_0's auc: 0.991198\n",
      "[47]\tvalid_0's auc: 0.991251\n",
      "[48]\tvalid_0's auc: 0.991198\n",
      "[49]\tvalid_0's auc: 0.991251\n",
      "[50]\tvalid_0's auc: 0.991146\n",
      "[51]\tvalid_0's auc: 0.991093\n",
      "[52]\tvalid_0's auc: 0.991146\n",
      "[53]\tvalid_0's auc: 0.991146\n",
      "[54]\tvalid_0's auc: 0.991357\n",
      "[55]\tvalid_0's auc: 0.991304\n",
      "[56]\tvalid_0's auc: 0.991462\n",
      "[57]\tvalid_0's auc: 0.991409\n",
      "[58]\tvalid_0's auc: 0.991409\n",
      "[59]\tvalid_0's auc: 0.991462\n",
      "[60]\tvalid_0's auc: 0.991462\n",
      "[61]\tvalid_0's auc: 0.991673\n",
      "[62]\tvalid_0's auc: 0.99162\n",
      "[63]\tvalid_0's auc: 0.991884\n",
      "[64]\tvalid_0's auc: 0.991778\n",
      "[65]\tvalid_0's auc: 0.991673\n",
      "[66]\tvalid_0's auc: 0.991726\n",
      "[67]\tvalid_0's auc: 0.991831\n",
      "[68]\tvalid_0's auc: 0.991778\n",
      "[69]\tvalid_0's auc: 0.991831\n",
      "[70]\tvalid_0's auc: 0.99162\n",
      "[71]\tvalid_0's auc: 0.991884\n",
      "[72]\tvalid_0's auc: 0.991936\n",
      "[73]\tvalid_0's auc: 0.992094\n",
      "[74]\tvalid_0's auc: 0.9922\n",
      "[75]\tvalid_0's auc: 0.992042\n",
      "[76]\tvalid_0's auc: 0.9922\n",
      "[77]\tvalid_0's auc: 0.9922\n",
      "[78]\tvalid_0's auc: 0.992411\n",
      "[79]\tvalid_0's auc: 0.9922\n",
      "[80]\tvalid_0's auc: 0.992516\n",
      "[81]\tvalid_0's auc: 0.992832\n",
      "[82]\tvalid_0's auc: 0.992885\n",
      "[83]\tvalid_0's auc: 0.992885\n",
      "[84]\tvalid_0's auc: 0.992832\n",
      "[85]\tvalid_0's auc: 0.993096\n",
      "[86]\tvalid_0's auc: 0.993149\n",
      "[87]\tvalid_0's auc: 0.993149\n",
      "[88]\tvalid_0's auc: 0.993412\n",
      "[89]\tvalid_0's auc: 0.993623\n",
      "[90]\tvalid_0's auc: 0.993676\n",
      "[91]\tvalid_0's auc: 0.993412\n",
      "[92]\tvalid_0's auc: 0.99357\n",
      "[93]\tvalid_0's auc: 0.99357\n",
      "[94]\tvalid_0's auc: 0.993517\n",
      "[95]\tvalid_0's auc: 0.993623\n",
      "[96]\tvalid_0's auc: 0.993623\n",
      "[97]\tvalid_0's auc: 0.993465\n",
      "[98]\tvalid_0's auc: 0.993465\n",
      "[99]\tvalid_0's auc: 0.993465\n",
      "[100]\tvalid_0's auc: 0.993465\n",
      "[101]\tvalid_0's auc: 0.993676\n",
      "[102]\tvalid_0's auc: 0.993728\n",
      "[103]\tvalid_0's auc: 0.99357\n",
      "[104]\tvalid_0's auc: 0.99357\n",
      "[105]\tvalid_0's auc: 0.99357\n",
      "[106]\tvalid_0's auc: 0.993517\n",
      "[107]\tvalid_0's auc: 0.993623\n",
      "[108]\tvalid_0's auc: 0.993676\n",
      "[109]\tvalid_0's auc: 0.993834\n",
      "[110]\tvalid_0's auc: 0.994097\n",
      "[111]\tvalid_0's auc: 0.994255\n",
      "[112]\tvalid_0's auc: 0.99415\n",
      "[113]\tvalid_0's auc: 0.994203\n",
      "[114]\tvalid_0's auc: 0.994203\n",
      "[115]\tvalid_0's auc: 0.994308\n",
      "[116]\tvalid_0's auc: 0.994308\n",
      "[117]\tvalid_0's auc: 0.994255\n",
      "[118]\tvalid_0's auc: 0.994624\n",
      "[119]\tvalid_0's auc: 0.994782\n",
      "[120]\tvalid_0's auc: 0.994888\n",
      "[121]\tvalid_0's auc: 0.994835\n",
      "[122]\tvalid_0's auc: 0.99473\n",
      "[123]\tvalid_0's auc: 0.994835\n",
      "[124]\tvalid_0's auc: 0.994835\n",
      "[125]\tvalid_0's auc: 0.994572\n",
      "[126]\tvalid_0's auc: 0.99473\n",
      "[127]\tvalid_0's auc: 0.99473\n",
      "[128]\tvalid_0's auc: 0.99473\n",
      "[129]\tvalid_0's auc: 0.99473\n",
      "[130]\tvalid_0's auc: 0.994835\n",
      "[131]\tvalid_0's auc: 0.994835\n",
      "[132]\tvalid_0's auc: 0.994835\n",
      "[133]\tvalid_0's auc: 0.994888\n",
      "[134]\tvalid_0's auc: 0.995046\n",
      "[135]\tvalid_0's auc: 0.995151\n",
      "[136]\tvalid_0's auc: 0.995204\n",
      "[137]\tvalid_0's auc: 0.995309\n",
      "[138]\tvalid_0's auc: 0.995362\n",
      "[139]\tvalid_0's auc: 0.995415\n",
      "[140]\tvalid_0's auc: 0.995415\n",
      "[141]\tvalid_0's auc: 0.995573\n",
      "[142]\tvalid_0's auc: 0.995731\n",
      "[143]\tvalid_0's auc: 0.995626\n",
      "[144]\tvalid_0's auc: 0.995678\n",
      "[145]\tvalid_0's auc: 0.995626\n",
      "[146]\tvalid_0's auc: 0.995678\n",
      "[147]\tvalid_0's auc: 0.995731\n",
      "[148]\tvalid_0's auc: 0.995784\n",
      "[149]\tvalid_0's auc: 0.995784\n",
      "[150]\tvalid_0's auc: 0.995836\n",
      "[151]\tvalid_0's auc: 0.995889\n",
      "[152]\tvalid_0's auc: 0.995889\n",
      "[153]\tvalid_0's auc: 0.995942\n",
      "[154]\tvalid_0's auc: 0.995836\n",
      "[155]\tvalid_0's auc: 0.995889\n",
      "[156]\tvalid_0's auc: 0.995942\n",
      "[157]\tvalid_0's auc: 0.995942\n",
      "[158]\tvalid_0's auc: 0.995942\n",
      "[159]\tvalid_0's auc: 0.995889\n",
      "[160]\tvalid_0's auc: 0.995889\n",
      "[161]\tvalid_0's auc: 0.995942\n",
      "[162]\tvalid_0's auc: 0.995942\n",
      "[163]\tvalid_0's auc: 0.995889\n",
      "[164]\tvalid_0's auc: 0.995942\n",
      "[165]\tvalid_0's auc: 0.995942\n",
      "[166]\tvalid_0's auc: 0.995942\n",
      "[167]\tvalid_0's auc: 0.995942\n",
      "[168]\tvalid_0's auc: 0.995995\n",
      "[169]\tvalid_0's auc: 0.995995\n",
      "[170]\tvalid_0's auc: 0.995995\n",
      "[171]\tvalid_0's auc: 0.995942\n",
      "[172]\tvalid_0's auc: 0.995942\n",
      "[173]\tvalid_0's auc: 0.995942\n",
      "[174]\tvalid_0's auc: 0.995889\n",
      "[175]\tvalid_0's auc: 0.995889\n",
      "[176]\tvalid_0's auc: 0.995942\n",
      "[177]\tvalid_0's auc: 0.995889\n",
      "[178]\tvalid_0's auc: 0.995942\n",
      "[179]\tvalid_0's auc: 0.996047\n",
      "[180]\tvalid_0's auc: 0.996047\n",
      "[181]\tvalid_0's auc: 0.996205\n",
      "[182]\tvalid_0's auc: 0.996205\n",
      "[183]\tvalid_0's auc: 0.996258\n",
      "[184]\tvalid_0's auc: 0.996258\n",
      "[185]\tvalid_0's auc: 0.996258\n",
      "[186]\tvalid_0's auc: 0.996258\n",
      "[187]\tvalid_0's auc: 0.996258\n",
      "[188]\tvalid_0's auc: 0.996258\n",
      "[189]\tvalid_0's auc: 0.996258\n",
      "[190]\tvalid_0's auc: 0.996258\n",
      "[191]\tvalid_0's auc: 0.996258\n",
      "[192]\tvalid_0's auc: 0.996363\n",
      "[193]\tvalid_0's auc: 0.996363\n",
      "[194]\tvalid_0's auc: 0.996363\n",
      "[195]\tvalid_0's auc: 0.996311\n",
      "[196]\tvalid_0's auc: 0.996258\n",
      "[197]\tvalid_0's auc: 0.996205\n",
      "[198]\tvalid_0's auc: 0.996205\n",
      "[199]\tvalid_0's auc: 0.996205\n",
      "[200]\tvalid_0's auc: 0.9961\n",
      "[201]\tvalid_0's auc: 0.9961\n",
      "[202]\tvalid_0's auc: 0.9961\n",
      "[203]\tvalid_0's auc: 0.996153\n",
      "[204]\tvalid_0's auc: 0.996258\n",
      "[205]\tvalid_0's auc: 0.996363\n",
      "[206]\tvalid_0's auc: 0.996311\n",
      "[207]\tvalid_0's auc: 0.996258\n",
      "[208]\tvalid_0's auc: 0.996258\n",
      "[209]\tvalid_0's auc: 0.996258\n",
      "[210]\tvalid_0's auc: 0.996258\n",
      "[211]\tvalid_0's auc: 0.996311\n",
      "[212]\tvalid_0's auc: 0.996311\n",
      "[213]\tvalid_0's auc: 0.996258\n",
      "[214]\tvalid_0's auc: 0.996258\n",
      "[215]\tvalid_0's auc: 0.996258\n",
      "[216]\tvalid_0's auc: 0.996258\n",
      "[217]\tvalid_0's auc: 0.996258\n",
      "[218]\tvalid_0's auc: 0.996258\n",
      "[219]\tvalid_0's auc: 0.996258\n",
      "[220]\tvalid_0's auc: 0.996258\n",
      "[221]\tvalid_0's auc: 0.996311\n",
      "[222]\tvalid_0's auc: 0.996311\n",
      "[223]\tvalid_0's auc: 0.996311\n",
      "[224]\tvalid_0's auc: 0.996311\n",
      "[225]\tvalid_0's auc: 0.996311\n",
      "[226]\tvalid_0's auc: 0.996311\n",
      "[227]\tvalid_0's auc: 0.996363\n",
      "[228]\tvalid_0's auc: 0.996363\n",
      "[229]\tvalid_0's auc: 0.996363\n",
      "[230]\tvalid_0's auc: 0.996416\n",
      "[231]\tvalid_0's auc: 0.996416\n",
      "[232]\tvalid_0's auc: 0.996363\n",
      "[233]\tvalid_0's auc: 0.996363\n",
      "[234]\tvalid_0's auc: 0.996363\n",
      "[235]\tvalid_0's auc: 0.996311\n",
      "[236]\tvalid_0's auc: 0.996311\n",
      "[237]\tvalid_0's auc: 0.996311\n",
      "[238]\tvalid_0's auc: 0.996311\n",
      "[239]\tvalid_0's auc: 0.996311\n",
      "[240]\tvalid_0's auc: 0.996363\n",
      "[241]\tvalid_0's auc: 0.996416\n",
      "[242]\tvalid_0's auc: 0.996469\n",
      "[243]\tvalid_0's auc: 0.996522\n",
      "[244]\tvalid_0's auc: 0.996416\n",
      "[245]\tvalid_0's auc: 0.996469\n",
      "[246]\tvalid_0's auc: 0.996416\n",
      "[247]\tvalid_0's auc: 0.996416\n",
      "[248]\tvalid_0's auc: 0.996311\n",
      "[249]\tvalid_0's auc: 0.996311\n",
      "[250]\tvalid_0's auc: 0.996469\n",
      "[251]\tvalid_0's auc: 0.996363\n",
      "[252]\tvalid_0's auc: 0.996363\n",
      "[253]\tvalid_0's auc: 0.996416\n",
      "[254]\tvalid_0's auc: 0.996469\n",
      "[255]\tvalid_0's auc: 0.996416\n",
      "[256]\tvalid_0's auc: 0.996469\n",
      "[257]\tvalid_0's auc: 0.996469\n",
      "[258]\tvalid_0's auc: 0.996469\n",
      "[259]\tvalid_0's auc: 0.996469\n",
      "[260]\tvalid_0's auc: 0.996574\n",
      "[261]\tvalid_0's auc: 0.996522\n",
      "[262]\tvalid_0's auc: 0.996522\n",
      "[263]\tvalid_0's auc: 0.996522\n",
      "[264]\tvalid_0's auc: 0.996574\n",
      "[265]\tvalid_0's auc: 0.996522\n",
      "[266]\tvalid_0's auc: 0.996522\n",
      "[267]\tvalid_0's auc: 0.996522\n",
      "[268]\tvalid_0's auc: 0.996522\n",
      "[269]\tvalid_0's auc: 0.996522\n",
      "[270]\tvalid_0's auc: 0.996522\n",
      "[271]\tvalid_0's auc: 0.996522\n",
      "[272]\tvalid_0's auc: 0.996522\n",
      "[273]\tvalid_0's auc: 0.996574\n",
      "[274]\tvalid_0's auc: 0.996574\n",
      "[275]\tvalid_0's auc: 0.996574\n",
      "[276]\tvalid_0's auc: 0.996627\n",
      "[277]\tvalid_0's auc: 0.996627\n",
      "[278]\tvalid_0's auc: 0.996732\n",
      "[279]\tvalid_0's auc: 0.99668\n",
      "[280]\tvalid_0's auc: 0.99668\n",
      "[281]\tvalid_0's auc: 0.996627\n",
      "[282]\tvalid_0's auc: 0.99668\n",
      "[283]\tvalid_0's auc: 0.99668\n",
      "[284]\tvalid_0's auc: 0.996627\n",
      "[285]\tvalid_0's auc: 0.996627\n",
      "[286]\tvalid_0's auc: 0.996627\n",
      "[287]\tvalid_0's auc: 0.996627\n",
      "[288]\tvalid_0's auc: 0.996627\n",
      "[289]\tvalid_0's auc: 0.996627\n",
      "[290]\tvalid_0's auc: 0.996574\n",
      "[291]\tvalid_0's auc: 0.996627\n",
      "[292]\tvalid_0's auc: 0.996574\n",
      "[293]\tvalid_0's auc: 0.996627\n",
      "[294]\tvalid_0's auc: 0.996522\n",
      "[295]\tvalid_0's auc: 0.996627\n",
      "[296]\tvalid_0's auc: 0.996574\n",
      "[297]\tvalid_0's auc: 0.996522\n",
      "[298]\tvalid_0's auc: 0.996627\n",
      "[299]\tvalid_0's auc: 0.996627\n",
      "[300]\tvalid_0's auc: 0.996627\n",
      "[301]\tvalid_0's auc: 0.996627\n",
      "[302]\tvalid_0's auc: 0.996574\n",
      "[303]\tvalid_0's auc: 0.996627\n",
      "[304]\tvalid_0's auc: 0.996574\n",
      "[305]\tvalid_0's auc: 0.996574\n",
      "[306]\tvalid_0's auc: 0.996522\n",
      "[307]\tvalid_0's auc: 0.996522\n",
      "[308]\tvalid_0's auc: 0.996522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[309]\tvalid_0's auc: 0.996522\n",
      "[310]\tvalid_0's auc: 0.996522\n",
      "[311]\tvalid_0's auc: 0.996574\n",
      "[312]\tvalid_0's auc: 0.996574\n",
      "[313]\tvalid_0's auc: 0.996574\n",
      "[314]\tvalid_0's auc: 0.996574\n",
      "[315]\tvalid_0's auc: 0.996574\n",
      "[316]\tvalid_0's auc: 0.996574\n",
      "[317]\tvalid_0's auc: 0.996574\n",
      "[318]\tvalid_0's auc: 0.996574\n",
      "[319]\tvalid_0's auc: 0.996574\n",
      "[320]\tvalid_0's auc: 0.996574\n",
      "[321]\tvalid_0's auc: 0.996574\n",
      "[322]\tvalid_0's auc: 0.996574\n",
      "[323]\tvalid_0's auc: 0.996574\n",
      "[324]\tvalid_0's auc: 0.996574\n",
      "[325]\tvalid_0's auc: 0.996574\n",
      "[326]\tvalid_0's auc: 0.996522\n",
      "[327]\tvalid_0's auc: 0.996522\n",
      "[328]\tvalid_0's auc: 0.996522\n",
      "[329]\tvalid_0's auc: 0.996522\n",
      "[330]\tvalid_0's auc: 0.996522\n",
      "[331]\tvalid_0's auc: 0.996574\n",
      "[332]\tvalid_0's auc: 0.996627\n",
      "[333]\tvalid_0's auc: 0.996627\n",
      "[334]\tvalid_0's auc: 0.996627\n",
      "[335]\tvalid_0's auc: 0.99668\n",
      "[336]\tvalid_0's auc: 0.99668\n",
      "[337]\tvalid_0's auc: 0.996732\n",
      "[338]\tvalid_0's auc: 0.996732\n",
      "[339]\tvalid_0's auc: 0.996732\n",
      "[340]\tvalid_0's auc: 0.996785\n",
      "[341]\tvalid_0's auc: 0.996838\n",
      "[342]\tvalid_0's auc: 0.996785\n",
      "[343]\tvalid_0's auc: 0.996838\n",
      "[344]\tvalid_0's auc: 0.996785\n",
      "[345]\tvalid_0's auc: 0.996785\n",
      "[346]\tvalid_0's auc: 0.996785\n",
      "[347]\tvalid_0's auc: 0.996785\n",
      "[348]\tvalid_0's auc: 0.996785\n",
      "[349]\tvalid_0's auc: 0.996732\n",
      "[350]\tvalid_0's auc: 0.996732\n",
      "[351]\tvalid_0's auc: 0.996732\n",
      "[352]\tvalid_0's auc: 0.996732\n",
      "[353]\tvalid_0's auc: 0.996732\n",
      "[354]\tvalid_0's auc: 0.996732\n",
      "[355]\tvalid_0's auc: 0.996732\n",
      "[356]\tvalid_0's auc: 0.996732\n",
      "[357]\tvalid_0's auc: 0.996732\n",
      "[358]\tvalid_0's auc: 0.996785\n",
      "[359]\tvalid_0's auc: 0.996785\n",
      "[360]\tvalid_0's auc: 0.996785\n",
      "[361]\tvalid_0's auc: 0.996785\n",
      "[362]\tvalid_0's auc: 0.996785\n",
      "[363]\tvalid_0's auc: 0.996785\n",
      "[364]\tvalid_0's auc: 0.996785\n",
      "[365]\tvalid_0's auc: 0.996785\n",
      "[366]\tvalid_0's auc: 0.996785\n",
      "[367]\tvalid_0's auc: 0.996732\n",
      "[368]\tvalid_0's auc: 0.996732\n",
      "[369]\tvalid_0's auc: 0.996732\n",
      "[370]\tvalid_0's auc: 0.996732\n",
      "[371]\tvalid_0's auc: 0.996732\n",
      "[372]\tvalid_0's auc: 0.996732\n",
      "[373]\tvalid_0's auc: 0.996732\n",
      "[374]\tvalid_0's auc: 0.996732\n",
      "[375]\tvalid_0's auc: 0.996732\n",
      "[376]\tvalid_0's auc: 0.996732\n",
      "[377]\tvalid_0's auc: 0.99668\n",
      "[378]\tvalid_0's auc: 0.99668\n",
      "[379]\tvalid_0's auc: 0.99668\n",
      "[380]\tvalid_0's auc: 0.99668\n",
      "[381]\tvalid_0's auc: 0.99668\n",
      "[382]\tvalid_0's auc: 0.996627\n",
      "[383]\tvalid_0's auc: 0.99668\n",
      "[384]\tvalid_0's auc: 0.99668\n",
      "[385]\tvalid_0's auc: 0.99668\n",
      "[386]\tvalid_0's auc: 0.996732\n",
      "[387]\tvalid_0's auc: 0.996732\n",
      "[388]\tvalid_0's auc: 0.996732\n",
      "[389]\tvalid_0's auc: 0.996732\n",
      "[390]\tvalid_0's auc: 0.996732\n",
      "[391]\tvalid_0's auc: 0.996732\n",
      "[392]\tvalid_0's auc: 0.996732\n",
      "[393]\tvalid_0's auc: 0.99668\n",
      "[394]\tvalid_0's auc: 0.99668\n",
      "[395]\tvalid_0's auc: 0.996627\n",
      "[396]\tvalid_0's auc: 0.996627\n",
      "[397]\tvalid_0's auc: 0.996627\n",
      "[398]\tvalid_0's auc: 0.996627\n",
      "[399]\tvalid_0's auc: 0.996627\n",
      "[400]\tvalid_0's auc: 0.996627\n",
      "[401]\tvalid_0's auc: 0.996627\n",
      "[402]\tvalid_0's auc: 0.99668\n",
      "[403]\tvalid_0's auc: 0.99668\n",
      "[404]\tvalid_0's auc: 0.99668\n",
      "[405]\tvalid_0's auc: 0.99668\n",
      "[406]\tvalid_0's auc: 0.99668\n",
      "[407]\tvalid_0's auc: 0.99668\n",
      "[408]\tvalid_0's auc: 0.99668\n",
      "[409]\tvalid_0's auc: 0.996627\n",
      "[410]\tvalid_0's auc: 0.996627\n",
      "[411]\tvalid_0's auc: 0.996627\n",
      "[412]\tvalid_0's auc: 0.996627\n",
      "[413]\tvalid_0's auc: 0.996627\n",
      "[414]\tvalid_0's auc: 0.996627\n",
      "[415]\tvalid_0's auc: 0.996627\n",
      "[416]\tvalid_0's auc: 0.996627\n",
      "[417]\tvalid_0's auc: 0.996627\n",
      "[418]\tvalid_0's auc: 0.996627\n",
      "[419]\tvalid_0's auc: 0.996627\n",
      "[420]\tvalid_0's auc: 0.996627\n",
      "[421]\tvalid_0's auc: 0.996627\n",
      "[422]\tvalid_0's auc: 0.996627\n",
      "[423]\tvalid_0's auc: 0.996627\n",
      "[424]\tvalid_0's auc: 0.996627\n",
      "[425]\tvalid_0's auc: 0.996627\n",
      "[426]\tvalid_0's auc: 0.996627\n",
      "[427]\tvalid_0's auc: 0.996627\n",
      "[428]\tvalid_0's auc: 0.996627\n",
      "[429]\tvalid_0's auc: 0.996627\n",
      "[430]\tvalid_0's auc: 0.996627\n",
      "[431]\tvalid_0's auc: 0.996627\n",
      "[432]\tvalid_0's auc: 0.99668\n",
      "[433]\tvalid_0's auc: 0.99668\n",
      "[434]\tvalid_0's auc: 0.99668\n",
      "[435]\tvalid_0's auc: 0.996732\n",
      "[436]\tvalid_0's auc: 0.996732\n",
      "[437]\tvalid_0's auc: 0.996732\n",
      "[438]\tvalid_0's auc: 0.996732\n",
      "[439]\tvalid_0's auc: 0.996732\n",
      "[440]\tvalid_0's auc: 0.996732\n",
      "[441]\tvalid_0's auc: 0.996732\n",
      "[442]\tvalid_0's auc: 0.996732\n",
      "[443]\tvalid_0's auc: 0.996732\n",
      "[444]\tvalid_0's auc: 0.996732\n",
      "[445]\tvalid_0's auc: 0.99668\n",
      "[446]\tvalid_0's auc: 0.996627\n",
      "[447]\tvalid_0's auc: 0.99668\n",
      "[448]\tvalid_0's auc: 0.996732\n",
      "[449]\tvalid_0's auc: 0.99668\n",
      "[450]\tvalid_0's auc: 0.996627\n",
      "[451]\tvalid_0's auc: 0.99668\n",
      "[452]\tvalid_0's auc: 0.99668\n",
      "[453]\tvalid_0's auc: 0.99668\n",
      "[454]\tvalid_0's auc: 0.99668\n",
      "[455]\tvalid_0's auc: 0.99668\n",
      "[456]\tvalid_0's auc: 0.99668\n",
      "[457]\tvalid_0's auc: 0.99668\n",
      "[458]\tvalid_0's auc: 0.99668\n",
      "[459]\tvalid_0's auc: 0.99668\n",
      "[460]\tvalid_0's auc: 0.99668\n",
      "[461]\tvalid_0's auc: 0.99668\n",
      "[462]\tvalid_0's auc: 0.996732\n",
      "[463]\tvalid_0's auc: 0.996732\n",
      "[464]\tvalid_0's auc: 0.996732\n",
      "[465]\tvalid_0's auc: 0.996732\n",
      "[466]\tvalid_0's auc: 0.996732\n",
      "[467]\tvalid_0's auc: 0.996732\n",
      "[468]\tvalid_0's auc: 0.996732\n",
      "[469]\tvalid_0's auc: 0.996732\n",
      "[470]\tvalid_0's auc: 0.996732\n",
      "[471]\tvalid_0's auc: 0.996732\n",
      "[472]\tvalid_0's auc: 0.996732\n",
      "[473]\tvalid_0's auc: 0.996732\n",
      "[474]\tvalid_0's auc: 0.996785\n",
      "[475]\tvalid_0's auc: 0.996838\n",
      "[476]\tvalid_0's auc: 0.996838\n",
      "[477]\tvalid_0's auc: 0.996838\n",
      "[478]\tvalid_0's auc: 0.996732\n",
      "[479]\tvalid_0's auc: 0.996785\n",
      "[480]\tvalid_0's auc: 0.996785\n",
      "[481]\tvalid_0's auc: 0.996785\n",
      "[482]\tvalid_0's auc: 0.996785\n",
      "[483]\tvalid_0's auc: 0.996785\n",
      "[484]\tvalid_0's auc: 0.996785\n",
      "[485]\tvalid_0's auc: 0.996785\n",
      "[486]\tvalid_0's auc: 0.996785\n",
      "[487]\tvalid_0's auc: 0.996785\n",
      "[488]\tvalid_0's auc: 0.996785\n",
      "[489]\tvalid_0's auc: 0.996785\n",
      "[490]\tvalid_0's auc: 0.996785\n",
      "[491]\tvalid_0's auc: 0.996785\n",
      "[492]\tvalid_0's auc: 0.996785\n",
      "[493]\tvalid_0's auc: 0.996785\n",
      "[494]\tvalid_0's auc: 0.996785\n",
      "[495]\tvalid_0's auc: 0.996785\n",
      "[496]\tvalid_0's auc: 0.996785\n",
      "[497]\tvalid_0's auc: 0.996785\n",
      "[498]\tvalid_0's auc: 0.996785\n",
      "[499]\tvalid_0's auc: 0.996785\n",
      "[500]\tvalid_0's auc: 0.996785\n",
      "[501]\tvalid_0's auc: 0.996785\n",
      "[502]\tvalid_0's auc: 0.996785\n",
      "[503]\tvalid_0's auc: 0.996785\n",
      "[504]\tvalid_0's auc: 0.996785\n",
      "[505]\tvalid_0's auc: 0.996785\n",
      "[506]\tvalid_0's auc: 0.996785\n",
      "[507]\tvalid_0's auc: 0.996785\n",
      "[508]\tvalid_0's auc: 0.996785\n",
      "[509]\tvalid_0's auc: 0.996785\n",
      "[510]\tvalid_0's auc: 0.996785\n",
      "[511]\tvalid_0's auc: 0.996785\n",
      "[512]\tvalid_0's auc: 0.996785\n",
      "[513]\tvalid_0's auc: 0.996785\n",
      "[514]\tvalid_0's auc: 0.996785\n",
      "[515]\tvalid_0's auc: 0.996785\n",
      "[516]\tvalid_0's auc: 0.996785\n",
      "[517]\tvalid_0's auc: 0.996785\n",
      "[518]\tvalid_0's auc: 0.996785\n",
      "[519]\tvalid_0's auc: 0.996785\n",
      "[520]\tvalid_0's auc: 0.996785\n",
      "[521]\tvalid_0's auc: 0.996785\n",
      "[522]\tvalid_0's auc: 0.996785\n",
      "[523]\tvalid_0's auc: 0.996785\n",
      "[524]\tvalid_0's auc: 0.996785\n",
      "[525]\tvalid_0's auc: 0.996785\n",
      "[526]\tvalid_0's auc: 0.996785\n",
      "[527]\tvalid_0's auc: 0.996785\n",
      "[528]\tvalid_0's auc: 0.996785\n",
      "[529]\tvalid_0's auc: 0.996785\n",
      "[530]\tvalid_0's auc: 0.996785\n",
      "[531]\tvalid_0's auc: 0.996785\n",
      "[532]\tvalid_0's auc: 0.996785\n",
      "[533]\tvalid_0's auc: 0.996785\n",
      "[534]\tvalid_0's auc: 0.996785\n",
      "[535]\tvalid_0's auc: 0.996785\n",
      "[536]\tvalid_0's auc: 0.996785\n",
      "[537]\tvalid_0's auc: 0.996785\n",
      "[538]\tvalid_0's auc: 0.996785\n",
      "[539]\tvalid_0's auc: 0.996785\n",
      "[540]\tvalid_0's auc: 0.996785\n",
      "[541]\tvalid_0's auc: 0.996785\n",
      "Early stopping, best iteration is:\n",
      "[341]\tvalid_0's auc: 0.996838\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[1]\tvalid_0's auc: 0.949836\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[2]\tvalid_0's auc: 0.94912\n",
      "[3]\tvalid_0's auc: 0.97252\n",
      "[4]\tvalid_0's auc: 0.970612\n",
      "[5]\tvalid_0's auc: 0.969843\n",
      "[6]\tvalid_0's auc: 0.975594\n",
      "[7]\tvalid_0's auc: 0.977343\n",
      "[8]\tvalid_0's auc: 0.977687\n",
      "[9]\tvalid_0's auc: 0.978164\n",
      "[10]\tvalid_0's auc: 0.976892\n",
      "[11]\tvalid_0's auc: 0.978509\n",
      "[12]\tvalid_0's auc: 0.978217\n",
      "[13]\tvalid_0's auc: 0.978429\n",
      "[14]\tvalid_0's auc: 0.978853\n",
      "[15]\tvalid_0's auc: 0.97933\n",
      "[16]\tvalid_0's auc: 0.981397\n",
      "[17]\tvalid_0's auc: 0.981821\n",
      "[18]\tvalid_0's auc: 0.983729\n",
      "[19]\tvalid_0's auc: 0.983994\n",
      "[20]\tvalid_0's auc: 0.984842\n",
      "[21]\tvalid_0's auc: 0.985425\n",
      "[22]\tvalid_0's auc: 0.9841\n",
      "[23]\tvalid_0's auc: 0.983729\n",
      "[24]\tvalid_0's auc: 0.985955\n",
      "[25]\tvalid_0's auc: 0.985372\n",
      "[26]\tvalid_0's auc: 0.98516\n",
      "[27]\tvalid_0's auc: 0.984895\n",
      "[28]\tvalid_0's auc: 0.985054\n",
      "[29]\tvalid_0's auc: 0.984683\n",
      "[30]\tvalid_0's auc: 0.984842\n",
      "[31]\tvalid_0's auc: 0.985637\n",
      "[32]\tvalid_0's auc: 0.98675\n",
      "[33]\tvalid_0's auc: 0.986538\n",
      "[34]\tvalid_0's auc: 0.986273\n",
      "[35]\tvalid_0's auc: 0.986538\n",
      "[36]\tvalid_0's auc: 0.986432\n",
      "[37]\tvalid_0's auc: 0.985796\n",
      "[38]\tvalid_0's auc: 0.986432\n",
      "[39]\tvalid_0's auc: 0.986485\n",
      "[40]\tvalid_0's auc: 0.98622\n",
      "[41]\tvalid_0's auc: 0.98622\n",
      "[42]\tvalid_0's auc: 0.986114\n",
      "[43]\tvalid_0's auc: 0.986008\n",
      "[44]\tvalid_0's auc: 0.985478\n",
      "[45]\tvalid_0's auc: 0.985372\n",
      "[46]\tvalid_0's auc: 0.985637\n",
      "[47]\tvalid_0's auc: 0.985531\n",
      "[48]\tvalid_0's auc: 0.985531\n",
      "[49]\tvalid_0's auc: 0.985425\n",
      "[50]\tvalid_0's auc: 0.985425\n",
      "[51]\tvalid_0's auc: 0.985372\n",
      "[52]\tvalid_0's auc: 0.985478\n",
      "[53]\tvalid_0's auc: 0.985372\n",
      "[54]\tvalid_0's auc: 0.985319\n",
      "[55]\tvalid_0's auc: 0.985372\n",
      "[56]\tvalid_0's auc: 0.98516\n",
      "[57]\tvalid_0's auc: 0.985531\n",
      "[58]\tvalid_0's auc: 0.985902\n",
      "[59]\tvalid_0's auc: 0.985955\n",
      "[60]\tvalid_0's auc: 0.986167\n",
      "[61]\tvalid_0's auc: 0.986167\n",
      "[62]\tvalid_0's auc: 0.986061\n",
      "[63]\tvalid_0's auc: 0.985955\n",
      "[64]\tvalid_0's auc: 0.985955\n",
      "[65]\tvalid_0's auc: 0.985796\n",
      "[66]\tvalid_0's auc: 0.98569\n",
      "[67]\tvalid_0's auc: 0.985743\n",
      "[68]\tvalid_0's auc: 0.98569\n",
      "[69]\tvalid_0's auc: 0.985531\n",
      "[70]\tvalid_0's auc: 0.985584\n",
      "[71]\tvalid_0's auc: 0.985531\n",
      "[72]\tvalid_0's auc: 0.98569\n",
      "[73]\tvalid_0's auc: 0.985478\n",
      "[74]\tvalid_0's auc: 0.985319\n",
      "[75]\tvalid_0's auc: 0.985584\n",
      "[76]\tvalid_0's auc: 0.985531\n",
      "[77]\tvalid_0's auc: 0.985425\n",
      "[78]\tvalid_0's auc: 0.985372\n",
      "[79]\tvalid_0's auc: 0.985637\n",
      "[80]\tvalid_0's auc: 0.985743\n",
      "[81]\tvalid_0's auc: 0.986909\n",
      "[82]\tvalid_0's auc: 0.987492\n",
      "[83]\tvalid_0's auc: 0.987598\n",
      "[84]\tvalid_0's auc: 0.987704\n",
      "[85]\tvalid_0's auc: 0.98781\n",
      "[86]\tvalid_0's auc: 0.988605\n",
      "[87]\tvalid_0's auc: 0.988605\n",
      "[88]\tvalid_0's auc: 0.988605\n",
      "[89]\tvalid_0's auc: 0.988446\n",
      "[90]\tvalid_0's auc: 0.988499\n",
      "[91]\tvalid_0's auc: 0.988605\n",
      "[92]\tvalid_0's auc: 0.988552\n",
      "[93]\tvalid_0's auc: 0.988446\n",
      "[94]\tvalid_0's auc: 0.988552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95]\tvalid_0's auc: 0.988605\n",
      "[96]\tvalid_0's auc: 0.988605\n",
      "[97]\tvalid_0's auc: 0.988817\n",
      "[98]\tvalid_0's auc: 0.988923\n",
      "[99]\tvalid_0's auc: 0.988923\n",
      "[100]\tvalid_0's auc: 0.988817\n",
      "[101]\tvalid_0's auc: 0.988923\n",
      "[102]\tvalid_0's auc: 0.988658\n",
      "[103]\tvalid_0's auc: 0.988817\n",
      "[104]\tvalid_0's auc: 0.988817\n",
      "[105]\tvalid_0's auc: 0.988605\n",
      "[106]\tvalid_0's auc: 0.988605\n",
      "[107]\tvalid_0's auc: 0.988605\n",
      "[108]\tvalid_0's auc: 0.988817\n",
      "[109]\tvalid_0's auc: 0.98887\n",
      "[110]\tvalid_0's auc: 0.988923\n",
      "[111]\tvalid_0's auc: 0.989241\n",
      "[112]\tvalid_0's auc: 0.989771\n",
      "[113]\tvalid_0's auc: 0.989983\n",
      "[114]\tvalid_0's auc: 0.98993\n",
      "[115]\tvalid_0's auc: 0.989877\n",
      "[116]\tvalid_0's auc: 0.989506\n",
      "[117]\tvalid_0's auc: 0.989506\n",
      "[118]\tvalid_0's auc: 0.989453\n",
      "[119]\tvalid_0's auc: 0.989347\n",
      "[120]\tvalid_0's auc: 0.989294\n",
      "[121]\tvalid_0's auc: 0.989718\n",
      "[122]\tvalid_0's auc: 0.989983\n",
      "[123]\tvalid_0's auc: 0.989983\n",
      "[124]\tvalid_0's auc: 0.990248\n",
      "[125]\tvalid_0's auc: 0.990248\n",
      "[126]\tvalid_0's auc: 0.990301\n",
      "[127]\tvalid_0's auc: 0.99046\n",
      "[128]\tvalid_0's auc: 0.990513\n",
      "[129]\tvalid_0's auc: 0.990513\n",
      "[130]\tvalid_0's auc: 0.99046\n",
      "[131]\tvalid_0's auc: 0.99046\n",
      "[132]\tvalid_0's auc: 0.99046\n",
      "[133]\tvalid_0's auc: 0.99046\n",
      "[134]\tvalid_0's auc: 0.990407\n",
      "[135]\tvalid_0's auc: 0.99046\n",
      "[136]\tvalid_0's auc: 0.990407\n",
      "[137]\tvalid_0's auc: 0.990354\n",
      "[138]\tvalid_0's auc: 0.990354\n",
      "[139]\tvalid_0's auc: 0.990248\n",
      "[140]\tvalid_0's auc: 0.990301\n",
      "[141]\tvalid_0's auc: 0.990619\n",
      "[142]\tvalid_0's auc: 0.990831\n",
      "[143]\tvalid_0's auc: 0.990725\n",
      "[144]\tvalid_0's auc: 0.990778\n",
      "[145]\tvalid_0's auc: 0.990778\n",
      "[146]\tvalid_0's auc: 0.990831\n",
      "[147]\tvalid_0's auc: 0.990725\n",
      "[148]\tvalid_0's auc: 0.990831\n",
      "[149]\tvalid_0's auc: 0.990884\n",
      "[150]\tvalid_0's auc: 0.990778\n",
      "[151]\tvalid_0's auc: 0.990619\n",
      "[152]\tvalid_0's auc: 0.990566\n",
      "[153]\tvalid_0's auc: 0.990566\n",
      "[154]\tvalid_0's auc: 0.990619\n",
      "[155]\tvalid_0's auc: 0.990566\n",
      "[156]\tvalid_0's auc: 0.990566\n",
      "[157]\tvalid_0's auc: 0.990513\n",
      "[158]\tvalid_0's auc: 0.990566\n",
      "[159]\tvalid_0's auc: 0.990619\n",
      "[160]\tvalid_0's auc: 0.990778\n",
      "[161]\tvalid_0's auc: 0.990672\n",
      "[162]\tvalid_0's auc: 0.990566\n",
      "[163]\tvalid_0's auc: 0.99046\n",
      "[164]\tvalid_0's auc: 0.990513\n",
      "[165]\tvalid_0's auc: 0.990407\n",
      "[166]\tvalid_0's auc: 0.990354\n",
      "[167]\tvalid_0's auc: 0.99046\n",
      "[168]\tvalid_0's auc: 0.990407\n",
      "[169]\tvalid_0's auc: 0.990513\n",
      "[170]\tvalid_0's auc: 0.990354\n",
      "[171]\tvalid_0's auc: 0.990354\n",
      "[172]\tvalid_0's auc: 0.990513\n",
      "[173]\tvalid_0's auc: 0.99046\n",
      "[174]\tvalid_0's auc: 0.990513\n",
      "[175]\tvalid_0's auc: 0.990513\n",
      "[176]\tvalid_0's auc: 0.990407\n",
      "[177]\tvalid_0's auc: 0.990407\n",
      "[178]\tvalid_0's auc: 0.990407\n",
      "[179]\tvalid_0's auc: 0.990407\n",
      "[180]\tvalid_0's auc: 0.990407\n",
      "[181]\tvalid_0's auc: 0.99046\n",
      "[182]\tvalid_0's auc: 0.990354\n",
      "[183]\tvalid_0's auc: 0.990301\n",
      "[184]\tvalid_0's auc: 0.990301\n",
      "[185]\tvalid_0's auc: 0.990354\n",
      "[186]\tvalid_0's auc: 0.990354\n",
      "[187]\tvalid_0's auc: 0.990513\n",
      "[188]\tvalid_0's auc: 0.990513\n",
      "[189]\tvalid_0's auc: 0.990513\n",
      "[190]\tvalid_0's auc: 0.990566\n",
      "[191]\tvalid_0's auc: 0.990619\n",
      "[192]\tvalid_0's auc: 0.990619\n",
      "[193]\tvalid_0's auc: 0.990566\n",
      "[194]\tvalid_0's auc: 0.990619\n",
      "[195]\tvalid_0's auc: 0.990778\n",
      "[196]\tvalid_0's auc: 0.990937\n",
      "[197]\tvalid_0's auc: 0.990937\n",
      "[198]\tvalid_0's auc: 0.990937\n",
      "[199]\tvalid_0's auc: 0.990884\n",
      "[200]\tvalid_0's auc: 0.990884\n",
      "[201]\tvalid_0's auc: 0.990884\n",
      "[202]\tvalid_0's auc: 0.990831\n",
      "[203]\tvalid_0's auc: 0.990884\n",
      "[204]\tvalid_0's auc: 0.990725\n",
      "[205]\tvalid_0's auc: 0.990672\n",
      "[206]\tvalid_0's auc: 0.990778\n",
      "[207]\tvalid_0's auc: 0.990884\n",
      "[208]\tvalid_0's auc: 0.991043\n",
      "[209]\tvalid_0's auc: 0.991096\n",
      "[210]\tvalid_0's auc: 0.991149\n",
      "[211]\tvalid_0's auc: 0.991149\n",
      "[212]\tvalid_0's auc: 0.991255\n",
      "[213]\tvalid_0's auc: 0.991255\n",
      "[214]\tvalid_0's auc: 0.991255\n",
      "[215]\tvalid_0's auc: 0.991255\n",
      "[216]\tvalid_0's auc: 0.991255\n",
      "[217]\tvalid_0's auc: 0.991255\n",
      "[218]\tvalid_0's auc: 0.991308\n",
      "[219]\tvalid_0's auc: 0.991308\n",
      "[220]\tvalid_0's auc: 0.991255\n",
      "[221]\tvalid_0's auc: 0.991202\n",
      "[222]\tvalid_0's auc: 0.991202\n",
      "[223]\tvalid_0's auc: 0.991149\n",
      "[224]\tvalid_0's auc: 0.991149\n",
      "[225]\tvalid_0's auc: 0.991202\n",
      "[226]\tvalid_0's auc: 0.991467\n",
      "[227]\tvalid_0's auc: 0.991361\n",
      "[228]\tvalid_0's auc: 0.991096\n",
      "[229]\tvalid_0's auc: 0.991096\n",
      "[230]\tvalid_0's auc: 0.991043\n",
      "[231]\tvalid_0's auc: 0.99099\n",
      "[232]\tvalid_0's auc: 0.990778\n",
      "[233]\tvalid_0's auc: 0.990725\n",
      "[234]\tvalid_0's auc: 0.990778\n",
      "[235]\tvalid_0's auc: 0.990884\n",
      "[236]\tvalid_0's auc: 0.990884\n",
      "[237]\tvalid_0's auc: 0.990778\n",
      "[238]\tvalid_0's auc: 0.990778\n",
      "[239]\tvalid_0's auc: 0.990831\n",
      "[240]\tvalid_0's auc: 0.990884\n",
      "[241]\tvalid_0's auc: 0.990831\n",
      "[242]\tvalid_0's auc: 0.990831\n",
      "[243]\tvalid_0's auc: 0.990831\n",
      "[244]\tvalid_0's auc: 0.990831\n",
      "[245]\tvalid_0's auc: 0.990778\n",
      "[246]\tvalid_0's auc: 0.990725\n",
      "[247]\tvalid_0's auc: 0.990725\n",
      "[248]\tvalid_0's auc: 0.990672\n",
      "[249]\tvalid_0's auc: 0.990725\n",
      "[250]\tvalid_0's auc: 0.990831\n",
      "[251]\tvalid_0's auc: 0.990778\n",
      "[252]\tvalid_0's auc: 0.990831\n",
      "[253]\tvalid_0's auc: 0.990884\n",
      "[254]\tvalid_0's auc: 0.990884\n",
      "[255]\tvalid_0's auc: 0.990884\n",
      "[256]\tvalid_0's auc: 0.990831\n",
      "[257]\tvalid_0's auc: 0.990831\n",
      "[258]\tvalid_0's auc: 0.990831\n",
      "[259]\tvalid_0's auc: 0.990831\n",
      "[260]\tvalid_0's auc: 0.990831\n",
      "[261]\tvalid_0's auc: 0.990778\n",
      "[262]\tvalid_0's auc: 0.990831\n",
      "[263]\tvalid_0's auc: 0.990725\n",
      "[264]\tvalid_0's auc: 0.990725\n",
      "[265]\tvalid_0's auc: 0.990778\n",
      "[266]\tvalid_0's auc: 0.990778\n",
      "[267]\tvalid_0's auc: 0.990778\n",
      "[268]\tvalid_0's auc: 0.990884\n",
      "[269]\tvalid_0's auc: 0.99099\n",
      "[270]\tvalid_0's auc: 0.99099\n",
      "[271]\tvalid_0's auc: 0.990937\n",
      "[272]\tvalid_0's auc: 0.990937\n",
      "[273]\tvalid_0's auc: 0.990884\n",
      "[274]\tvalid_0's auc: 0.990778\n",
      "[275]\tvalid_0's auc: 0.990831\n",
      "[276]\tvalid_0's auc: 0.990831\n",
      "[277]\tvalid_0's auc: 0.990884\n",
      "[278]\tvalid_0's auc: 0.990884\n",
      "[279]\tvalid_0's auc: 0.99099\n",
      "[280]\tvalid_0's auc: 0.991043\n",
      "[281]\tvalid_0's auc: 0.991043\n",
      "[282]\tvalid_0's auc: 0.991096\n",
      "[283]\tvalid_0's auc: 0.991096\n",
      "[284]\tvalid_0's auc: 0.991043\n",
      "[285]\tvalid_0's auc: 0.991043\n",
      "[286]\tvalid_0's auc: 0.991096\n",
      "[287]\tvalid_0's auc: 0.991043\n",
      "[288]\tvalid_0's auc: 0.991096\n",
      "[289]\tvalid_0's auc: 0.991096\n",
      "[290]\tvalid_0's auc: 0.99099\n",
      "[291]\tvalid_0's auc: 0.991043\n",
      "[292]\tvalid_0's auc: 0.991043\n",
      "[293]\tvalid_0's auc: 0.991043\n",
      "[294]\tvalid_0's auc: 0.991043\n",
      "[295]\tvalid_0's auc: 0.991096\n",
      "[296]\tvalid_0's auc: 0.991149\n",
      "[297]\tvalid_0's auc: 0.991149\n",
      "[298]\tvalid_0's auc: 0.991255\n",
      "[299]\tvalid_0's auc: 0.991255\n",
      "[300]\tvalid_0's auc: 0.991202\n",
      "[301]\tvalid_0's auc: 0.991149\n",
      "[302]\tvalid_0's auc: 0.991149\n",
      "[303]\tvalid_0's auc: 0.991096\n",
      "[304]\tvalid_0's auc: 0.991096\n",
      "[305]\tvalid_0's auc: 0.991096\n",
      "[306]\tvalid_0's auc: 0.991149\n",
      "[307]\tvalid_0's auc: 0.991096\n",
      "[308]\tvalid_0's auc: 0.991255\n",
      "[309]\tvalid_0's auc: 0.991202\n",
      "[310]\tvalid_0's auc: 0.991149\n",
      "[311]\tvalid_0's auc: 0.991149\n",
      "[312]\tvalid_0's auc: 0.991202\n",
      "[313]\tvalid_0's auc: 0.991149\n",
      "[314]\tvalid_0's auc: 0.991149\n",
      "[315]\tvalid_0's auc: 0.991149\n",
      "[316]\tvalid_0's auc: 0.991149\n",
      "[317]\tvalid_0's auc: 0.991096\n",
      "[318]\tvalid_0's auc: 0.991096\n",
      "[319]\tvalid_0's auc: 0.991043\n",
      "[320]\tvalid_0's auc: 0.991043\n",
      "[321]\tvalid_0's auc: 0.991096\n",
      "[322]\tvalid_0's auc: 0.991096\n",
      "[323]\tvalid_0's auc: 0.991149\n",
      "[324]\tvalid_0's auc: 0.991202\n",
      "[325]\tvalid_0's auc: 0.991308\n",
      "[326]\tvalid_0's auc: 0.991202\n",
      "[327]\tvalid_0's auc: 0.991149\n",
      "[328]\tvalid_0's auc: 0.991202\n",
      "[329]\tvalid_0's auc: 0.991255\n",
      "[330]\tvalid_0's auc: 0.991255\n",
      "[331]\tvalid_0's auc: 0.991255\n",
      "[332]\tvalid_0's auc: 0.991255\n",
      "[333]\tvalid_0's auc: 0.991255\n",
      "[334]\tvalid_0's auc: 0.991202\n",
      "[335]\tvalid_0's auc: 0.991202\n",
      "[336]\tvalid_0's auc: 0.991202\n",
      "[337]\tvalid_0's auc: 0.991202\n",
      "[338]\tvalid_0's auc: 0.991202\n",
      "[339]\tvalid_0's auc: 0.991202\n",
      "[340]\tvalid_0's auc: 0.991255\n",
      "[341]\tvalid_0's auc: 0.991255\n",
      "[342]\tvalid_0's auc: 0.991202\n",
      "[343]\tvalid_0's auc: 0.991096\n",
      "[344]\tvalid_0's auc: 0.991096\n",
      "[345]\tvalid_0's auc: 0.991043\n",
      "[346]\tvalid_0's auc: 0.991149\n",
      "[347]\tvalid_0's auc: 0.991149\n",
      "[348]\tvalid_0's auc: 0.991149\n",
      "[349]\tvalid_0's auc: 0.991149\n",
      "[350]\tvalid_0's auc: 0.991149\n",
      "[351]\tvalid_0's auc: 0.991149\n",
      "[352]\tvalid_0's auc: 0.991149\n",
      "[353]\tvalid_0's auc: 0.99099\n",
      "[354]\tvalid_0's auc: 0.991043\n",
      "[355]\tvalid_0's auc: 0.991043\n",
      "[356]\tvalid_0's auc: 0.991043\n",
      "[357]\tvalid_0's auc: 0.991043\n",
      "[358]\tvalid_0's auc: 0.990884\n",
      "[359]\tvalid_0's auc: 0.991043\n",
      "[360]\tvalid_0's auc: 0.991043\n",
      "[361]\tvalid_0's auc: 0.991043\n",
      "[362]\tvalid_0's auc: 0.991043\n",
      "[363]\tvalid_0's auc: 0.991043\n",
      "[364]\tvalid_0's auc: 0.991043\n",
      "[365]\tvalid_0's auc: 0.991043\n",
      "[366]\tvalid_0's auc: 0.991096\n",
      "[367]\tvalid_0's auc: 0.991096\n",
      "[368]\tvalid_0's auc: 0.991096\n",
      "[369]\tvalid_0's auc: 0.991096\n",
      "[370]\tvalid_0's auc: 0.991043\n",
      "[371]\tvalid_0's auc: 0.991043\n",
      "[372]\tvalid_0's auc: 0.99099\n",
      "[373]\tvalid_0's auc: 0.99099\n",
      "[374]\tvalid_0's auc: 0.991043\n",
      "[375]\tvalid_0's auc: 0.991043\n",
      "[376]\tvalid_0's auc: 0.99099\n",
      "[377]\tvalid_0's auc: 0.991043\n",
      "[378]\tvalid_0's auc: 0.991043\n",
      "[379]\tvalid_0's auc: 0.991043\n",
      "[380]\tvalid_0's auc: 0.991043\n",
      "[381]\tvalid_0's auc: 0.991043\n",
      "[382]\tvalid_0's auc: 0.991096\n",
      "[383]\tvalid_0's auc: 0.991149\n",
      "[384]\tvalid_0's auc: 0.991149\n",
      "[385]\tvalid_0's auc: 0.991202\n",
      "[386]\tvalid_0's auc: 0.991202\n",
      "[387]\tvalid_0's auc: 0.991202\n",
      "[388]\tvalid_0's auc: 0.991202\n",
      "[389]\tvalid_0's auc: 0.991149\n",
      "[390]\tvalid_0's auc: 0.991202\n",
      "[391]\tvalid_0's auc: 0.991255\n",
      "[392]\tvalid_0's auc: 0.991202\n",
      "[393]\tvalid_0's auc: 0.991255\n",
      "[394]\tvalid_0's auc: 0.991255\n",
      "[395]\tvalid_0's auc: 0.991255\n",
      "[396]\tvalid_0's auc: 0.991255\n",
      "[397]\tvalid_0's auc: 0.991308\n",
      "[398]\tvalid_0's auc: 0.991255\n",
      "[399]\tvalid_0's auc: 0.991308\n",
      "[400]\tvalid_0's auc: 0.991308\n",
      "[401]\tvalid_0's auc: 0.991202\n",
      "[402]\tvalid_0's auc: 0.991255\n",
      "[403]\tvalid_0's auc: 0.991255\n",
      "[404]\tvalid_0's auc: 0.991255\n",
      "[405]\tvalid_0's auc: 0.991308\n",
      "[406]\tvalid_0's auc: 0.991414\n",
      "[407]\tvalid_0's auc: 0.991414\n",
      "[408]\tvalid_0's auc: 0.991361\n",
      "[409]\tvalid_0's auc: 0.991361\n",
      "[410]\tvalid_0's auc: 0.991308\n",
      "[411]\tvalid_0's auc: 0.991308\n",
      "[412]\tvalid_0's auc: 0.991308\n",
      "[413]\tvalid_0's auc: 0.991361\n",
      "[414]\tvalid_0's auc: 0.991361\n",
      "[415]\tvalid_0's auc: 0.991414\n",
      "[416]\tvalid_0's auc: 0.991414\n",
      "[417]\tvalid_0's auc: 0.991414\n",
      "[418]\tvalid_0's auc: 0.991414\n",
      "[419]\tvalid_0's auc: 0.991414\n",
      "[420]\tvalid_0's auc: 0.991414\n",
      "[421]\tvalid_0's auc: 0.991361\n",
      "[422]\tvalid_0's auc: 0.991414\n",
      "[423]\tvalid_0's auc: 0.991414\n",
      "[424]\tvalid_0's auc: 0.991414\n",
      "[425]\tvalid_0's auc: 0.991414\n",
      "[426]\tvalid_0's auc: 0.991414\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's auc: 0.991467\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[1]\tvalid_0's auc: 0.96688\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\tvalid_0's auc: 0.984396\n",
      "[3]\tvalid_0's auc: 0.991674\n",
      "[4]\tvalid_0's auc: 0.991797\n",
      "[5]\tvalid_0's auc: 0.992907\n",
      "[6]\tvalid_0's auc: 0.994449\n",
      "[7]\tvalid_0's auc: 0.993894\n",
      "[8]\tvalid_0's auc: 0.995128\n",
      "[9]\tvalid_0's auc: 0.995251\n",
      "[10]\tvalid_0's auc: 0.996114\n",
      "[11]\tvalid_0's auc: 0.996485\n",
      "[12]\tvalid_0's auc: 0.996485\n",
      "[13]\tvalid_0's auc: 0.996485\n",
      "[14]\tvalid_0's auc: 0.996485\n",
      "[15]\tvalid_0's auc: 0.996485\n",
      "[16]\tvalid_0's auc: 0.99667\n",
      "[17]\tvalid_0's auc: 0.996176\n",
      "[18]\tvalid_0's auc: 0.996053\n",
      "[19]\tvalid_0's auc: 0.996238\n",
      "[20]\tvalid_0's auc: 0.996238\n",
      "[21]\tvalid_0's auc: 0.996053\n",
      "[22]\tvalid_0's auc: 0.99667\n",
      "[23]\tvalid_0's auc: 0.996423\n",
      "[24]\tvalid_0's auc: 0.99667\n",
      "[25]\tvalid_0's auc: 0.99667\n",
      "[26]\tvalid_0's auc: 0.99667\n",
      "[27]\tvalid_0's auc: 0.99667\n",
      "[28]\tvalid_0's auc: 0.996793\n",
      "[29]\tvalid_0's auc: 0.99667\n",
      "[30]\tvalid_0's auc: 0.99704\n",
      "[31]\tvalid_0's auc: 0.996916\n",
      "[32]\tvalid_0's auc: 0.99704\n",
      "[33]\tvalid_0's auc: 0.99667\n",
      "[34]\tvalid_0's auc: 0.996793\n",
      "[35]\tvalid_0's auc: 0.996793\n",
      "[36]\tvalid_0's auc: 0.996916\n",
      "[37]\tvalid_0's auc: 0.99704\n",
      "[38]\tvalid_0's auc: 0.99704\n",
      "[39]\tvalid_0's auc: 0.997163\n",
      "[40]\tvalid_0's auc: 0.997163\n",
      "[41]\tvalid_0's auc: 0.997163\n",
      "[42]\tvalid_0's auc: 0.99704\n",
      "[43]\tvalid_0's auc: 0.996916\n",
      "[44]\tvalid_0's auc: 0.996916\n",
      "[45]\tvalid_0's auc: 0.996916\n",
      "[46]\tvalid_0's auc: 0.996916\n",
      "[47]\tvalid_0's auc: 0.996916\n",
      "[48]\tvalid_0's auc: 0.99704\n",
      "[49]\tvalid_0's auc: 0.996793\n",
      "[50]\tvalid_0's auc: 0.99704\n",
      "[51]\tvalid_0's auc: 0.996916\n",
      "[52]\tvalid_0's auc: 0.99704\n",
      "[53]\tvalid_0's auc: 0.997163\n",
      "[54]\tvalid_0's auc: 0.997286\n",
      "[55]\tvalid_0's auc: 0.997163\n",
      "[56]\tvalid_0's auc: 0.997163\n",
      "[57]\tvalid_0's auc: 0.99704\n",
      "[58]\tvalid_0's auc: 0.99704\n",
      "[59]\tvalid_0's auc: 0.997163\n",
      "[60]\tvalid_0's auc: 0.996916\n",
      "[61]\tvalid_0's auc: 0.996916\n",
      "[62]\tvalid_0's auc: 0.996546\n",
      "[63]\tvalid_0's auc: 0.996423\n",
      "[64]\tvalid_0's auc: 0.99667\n",
      "[65]\tvalid_0's auc: 0.996793\n",
      "[66]\tvalid_0's auc: 0.99667\n",
      "[67]\tvalid_0's auc: 0.996793\n",
      "[68]\tvalid_0's auc: 0.99667\n",
      "[69]\tvalid_0's auc: 0.996793\n",
      "[70]\tvalid_0's auc: 0.996793\n",
      "[71]\tvalid_0's auc: 0.996793\n",
      "[72]\tvalid_0's auc: 0.99667\n",
      "[73]\tvalid_0's auc: 0.99667\n",
      "[74]\tvalid_0's auc: 0.996546\n",
      "[75]\tvalid_0's auc: 0.996916\n",
      "[76]\tvalid_0's auc: 0.996916\n",
      "[77]\tvalid_0's auc: 0.996916\n",
      "[78]\tvalid_0's auc: 0.997163\n",
      "[79]\tvalid_0's auc: 0.997163\n",
      "[80]\tvalid_0's auc: 0.997286\n",
      "[81]\tvalid_0's auc: 0.99704\n",
      "[82]\tvalid_0's auc: 0.99704\n",
      "[83]\tvalid_0's auc: 0.997163\n",
      "[84]\tvalid_0's auc: 0.997163\n",
      "[85]\tvalid_0's auc: 0.99704\n",
      "[86]\tvalid_0's auc: 0.99741\n",
      "[87]\tvalid_0's auc: 0.997286\n",
      "[88]\tvalid_0's auc: 0.99741\n",
      "[89]\tvalid_0's auc: 0.997286\n",
      "[90]\tvalid_0's auc: 0.997286\n",
      "[91]\tvalid_0's auc: 0.99741\n",
      "[92]\tvalid_0's auc: 0.997163\n",
      "[93]\tvalid_0's auc: 0.997163\n",
      "[94]\tvalid_0's auc: 0.99704\n",
      "[95]\tvalid_0's auc: 0.997163\n",
      "[96]\tvalid_0's auc: 0.997163\n",
      "[97]\tvalid_0's auc: 0.99741\n",
      "[98]\tvalid_0's auc: 0.99741\n",
      "[99]\tvalid_0's auc: 0.997533\n",
      "[100]\tvalid_0's auc: 0.99741\n",
      "[101]\tvalid_0's auc: 0.99741\n",
      "[102]\tvalid_0's auc: 0.99741\n",
      "[103]\tvalid_0's auc: 0.99741\n",
      "[104]\tvalid_0's auc: 0.99741\n",
      "[105]\tvalid_0's auc: 0.99741\n",
      "[106]\tvalid_0's auc: 0.99741\n",
      "[107]\tvalid_0's auc: 0.99741\n",
      "[108]\tvalid_0's auc: 0.997533\n",
      "[109]\tvalid_0's auc: 0.997533\n",
      "[110]\tvalid_0's auc: 0.997533\n",
      "[111]\tvalid_0's auc: 0.997533\n",
      "[112]\tvalid_0's auc: 0.997533\n",
      "[113]\tvalid_0's auc: 0.997656\n",
      "[114]\tvalid_0's auc: 0.997656\n",
      "[115]\tvalid_0's auc: 0.99778\n",
      "[116]\tvalid_0's auc: 0.99778\n",
      "[117]\tvalid_0's auc: 0.998026\n",
      "[118]\tvalid_0's auc: 0.998026\n",
      "[119]\tvalid_0's auc: 0.997903\n",
      "[120]\tvalid_0's auc: 0.997903\n",
      "[121]\tvalid_0's auc: 0.998026\n",
      "[122]\tvalid_0's auc: 0.998026\n",
      "[123]\tvalid_0's auc: 0.998026\n",
      "[124]\tvalid_0's auc: 0.997903\n",
      "[125]\tvalid_0's auc: 0.998026\n",
      "[126]\tvalid_0's auc: 0.998026\n",
      "[127]\tvalid_0's auc: 0.998026\n",
      "[128]\tvalid_0's auc: 0.998026\n",
      "[129]\tvalid_0's auc: 0.998026\n",
      "[130]\tvalid_0's auc: 0.998026\n",
      "[131]\tvalid_0's auc: 0.998026\n",
      "[132]\tvalid_0's auc: 0.998026\n",
      "[133]\tvalid_0's auc: 0.997903\n",
      "[134]\tvalid_0's auc: 0.998026\n",
      "[135]\tvalid_0's auc: 0.998026\n",
      "[136]\tvalid_0's auc: 0.997903\n",
      "[137]\tvalid_0's auc: 0.997903\n",
      "[138]\tvalid_0's auc: 0.99778\n",
      "[139]\tvalid_0's auc: 0.99778\n",
      "[140]\tvalid_0's auc: 0.997656\n",
      "[141]\tvalid_0's auc: 0.997656\n",
      "[142]\tvalid_0's auc: 0.99778\n",
      "[143]\tvalid_0's auc: 0.997656\n",
      "[144]\tvalid_0's auc: 0.997656\n",
      "[145]\tvalid_0's auc: 0.99778\n",
      "[146]\tvalid_0's auc: 0.997533\n",
      "[147]\tvalid_0's auc: 0.997533\n",
      "[148]\tvalid_0's auc: 0.997656\n",
      "[149]\tvalid_0's auc: 0.997533\n",
      "[150]\tvalid_0's auc: 0.997533\n",
      "[151]\tvalid_0's auc: 0.997656\n",
      "[152]\tvalid_0's auc: 0.997533\n",
      "[153]\tvalid_0's auc: 0.997533\n",
      "[154]\tvalid_0's auc: 0.997533\n",
      "[155]\tvalid_0's auc: 0.99778\n",
      "[156]\tvalid_0's auc: 0.997656\n",
      "[157]\tvalid_0's auc: 0.997656\n",
      "[158]\tvalid_0's auc: 0.99778\n",
      "[159]\tvalid_0's auc: 0.99778\n",
      "[160]\tvalid_0's auc: 0.998026\n",
      "[161]\tvalid_0's auc: 0.998026\n",
      "[162]\tvalid_0's auc: 0.997903\n",
      "[163]\tvalid_0's auc: 0.997903\n",
      "[164]\tvalid_0's auc: 0.99778\n",
      "[165]\tvalid_0's auc: 0.997903\n",
      "[166]\tvalid_0's auc: 0.99778\n",
      "[167]\tvalid_0's auc: 0.99778\n",
      "[168]\tvalid_0's auc: 0.998026\n",
      "[169]\tvalid_0's auc: 0.998026\n",
      "[170]\tvalid_0's auc: 0.99815\n",
      "[171]\tvalid_0's auc: 0.99815\n",
      "[172]\tvalid_0's auc: 0.998026\n",
      "[173]\tvalid_0's auc: 0.998026\n",
      "[174]\tvalid_0's auc: 0.997903\n",
      "[175]\tvalid_0's auc: 0.997903\n",
      "[176]\tvalid_0's auc: 0.997903\n",
      "[177]\tvalid_0's auc: 0.997903\n",
      "[178]\tvalid_0's auc: 0.99778\n",
      "[179]\tvalid_0's auc: 0.99778\n",
      "[180]\tvalid_0's auc: 0.99778\n",
      "[181]\tvalid_0's auc: 0.99778\n",
      "[182]\tvalid_0's auc: 0.99778\n",
      "[183]\tvalid_0's auc: 0.99778\n",
      "[184]\tvalid_0's auc: 0.997903\n",
      "[185]\tvalid_0's auc: 0.997903\n",
      "[186]\tvalid_0's auc: 0.998026\n",
      "[187]\tvalid_0's auc: 0.998026\n",
      "[188]\tvalid_0's auc: 0.998026\n",
      "[189]\tvalid_0's auc: 0.99815\n",
      "[190]\tvalid_0's auc: 0.99815\n",
      "[191]\tvalid_0's auc: 0.998273\n",
      "[192]\tvalid_0's auc: 0.998273\n",
      "[193]\tvalid_0's auc: 0.99815\n",
      "[194]\tvalid_0's auc: 0.998396\n",
      "[195]\tvalid_0's auc: 0.998396\n",
      "[196]\tvalid_0's auc: 0.99852\n",
      "[197]\tvalid_0's auc: 0.998396\n",
      "[198]\tvalid_0's auc: 0.998396\n",
      "[199]\tvalid_0's auc: 0.998396\n",
      "[200]\tvalid_0's auc: 0.998396\n",
      "[201]\tvalid_0's auc: 0.998396\n",
      "[202]\tvalid_0's auc: 0.998273\n",
      "[203]\tvalid_0's auc: 0.998273\n",
      "[204]\tvalid_0's auc: 0.99815\n",
      "[205]\tvalid_0's auc: 0.998026\n",
      "[206]\tvalid_0's auc: 0.998273\n",
      "[207]\tvalid_0's auc: 0.998273\n",
      "[208]\tvalid_0's auc: 0.998396\n",
      "[209]\tvalid_0's auc: 0.998396\n",
      "[210]\tvalid_0's auc: 0.998396\n",
      "[211]\tvalid_0's auc: 0.998396\n",
      "[212]\tvalid_0's auc: 0.99852\n",
      "[213]\tvalid_0's auc: 0.998643\n",
      "[214]\tvalid_0's auc: 0.998643\n",
      "[215]\tvalid_0's auc: 0.99852\n",
      "[216]\tvalid_0's auc: 0.99852\n",
      "[217]\tvalid_0's auc: 0.99852\n",
      "[218]\tvalid_0's auc: 0.99852\n",
      "[219]\tvalid_0's auc: 0.998396\n",
      "[220]\tvalid_0's auc: 0.998396\n",
      "[221]\tvalid_0's auc: 0.998396\n",
      "[222]\tvalid_0's auc: 0.998396\n",
      "[223]\tvalid_0's auc: 0.99852\n",
      "[224]\tvalid_0's auc: 0.99852\n",
      "[225]\tvalid_0's auc: 0.99852\n",
      "[226]\tvalid_0's auc: 0.998396\n",
      "[227]\tvalid_0's auc: 0.998396\n",
      "[228]\tvalid_0's auc: 0.998396\n",
      "[229]\tvalid_0's auc: 0.998396\n",
      "[230]\tvalid_0's auc: 0.99852\n",
      "[231]\tvalid_0's auc: 0.998396\n",
      "[232]\tvalid_0's auc: 0.998273\n",
      "[233]\tvalid_0's auc: 0.998273\n",
      "[234]\tvalid_0's auc: 0.998273\n",
      "[235]\tvalid_0's auc: 0.998273\n",
      "[236]\tvalid_0's auc: 0.998273\n",
      "[237]\tvalid_0's auc: 0.998273\n",
      "[238]\tvalid_0's auc: 0.998396\n",
      "[239]\tvalid_0's auc: 0.998396\n",
      "[240]\tvalid_0's auc: 0.998396\n",
      "[241]\tvalid_0's auc: 0.998273\n",
      "[242]\tvalid_0's auc: 0.998273\n",
      "[243]\tvalid_0's auc: 0.998396\n",
      "[244]\tvalid_0's auc: 0.998273\n",
      "[245]\tvalid_0's auc: 0.998396\n",
      "[246]\tvalid_0's auc: 0.998273\n",
      "[247]\tvalid_0's auc: 0.998273\n",
      "[248]\tvalid_0's auc: 0.998273\n",
      "[249]\tvalid_0's auc: 0.998273\n",
      "[250]\tvalid_0's auc: 0.99815\n",
      "[251]\tvalid_0's auc: 0.99815\n",
      "[252]\tvalid_0's auc: 0.99815\n",
      "[253]\tvalid_0's auc: 0.99815\n",
      "[254]\tvalid_0's auc: 0.99815\n",
      "[255]\tvalid_0's auc: 0.99815\n",
      "[256]\tvalid_0's auc: 0.99815\n",
      "[257]\tvalid_0's auc: 0.998026\n",
      "[258]\tvalid_0's auc: 0.998026\n",
      "[259]\tvalid_0's auc: 0.998026\n",
      "[260]\tvalid_0's auc: 0.998026\n",
      "[261]\tvalid_0's auc: 0.998026\n",
      "[262]\tvalid_0's auc: 0.998026\n",
      "[263]\tvalid_0's auc: 0.998026\n",
      "[264]\tvalid_0's auc: 0.997903\n",
      "[265]\tvalid_0's auc: 0.997903\n",
      "[266]\tvalid_0's auc: 0.997903\n",
      "[267]\tvalid_0's auc: 0.997903\n",
      "[268]\tvalid_0's auc: 0.997903\n",
      "[269]\tvalid_0's auc: 0.997903\n",
      "[270]\tvalid_0's auc: 0.997656\n",
      "[271]\tvalid_0's auc: 0.997656\n",
      "[272]\tvalid_0's auc: 0.99741\n",
      "[273]\tvalid_0's auc: 0.99741\n",
      "[274]\tvalid_0's auc: 0.99741\n",
      "[275]\tvalid_0's auc: 0.997286\n",
      "[276]\tvalid_0's auc: 0.997286\n",
      "[277]\tvalid_0's auc: 0.997286\n",
      "[278]\tvalid_0's auc: 0.997286\n",
      "[279]\tvalid_0's auc: 0.99741\n",
      "[280]\tvalid_0's auc: 0.99741\n",
      "[281]\tvalid_0's auc: 0.997286\n",
      "[282]\tvalid_0's auc: 0.997286\n",
      "[283]\tvalid_0's auc: 0.997286\n",
      "[284]\tvalid_0's auc: 0.997286\n",
      "[285]\tvalid_0's auc: 0.99741\n",
      "[286]\tvalid_0's auc: 0.99741\n",
      "[287]\tvalid_0's auc: 0.99741\n",
      "[288]\tvalid_0's auc: 0.99741\n",
      "[289]\tvalid_0's auc: 0.99741\n",
      "[290]\tvalid_0's auc: 0.99741\n",
      "[291]\tvalid_0's auc: 0.99741\n",
      "[292]\tvalid_0's auc: 0.997286\n",
      "[293]\tvalid_0's auc: 0.997286\n",
      "[294]\tvalid_0's auc: 0.997286\n",
      "[295]\tvalid_0's auc: 0.99741\n",
      "[296]\tvalid_0's auc: 0.997656\n",
      "[297]\tvalid_0's auc: 0.997656\n",
      "[298]\tvalid_0's auc: 0.997903\n",
      "[299]\tvalid_0's auc: 0.99778\n",
      "[300]\tvalid_0's auc: 0.997903\n",
      "[301]\tvalid_0's auc: 0.997903\n",
      "[302]\tvalid_0's auc: 0.997903\n",
      "[303]\tvalid_0's auc: 0.997903\n",
      "[304]\tvalid_0's auc: 0.997656\n",
      "[305]\tvalid_0's auc: 0.99741\n",
      "[306]\tvalid_0's auc: 0.997533\n",
      "[307]\tvalid_0's auc: 0.99741\n",
      "[308]\tvalid_0's auc: 0.997533\n",
      "[309]\tvalid_0's auc: 0.997533\n",
      "[310]\tvalid_0's auc: 0.997656\n",
      "[311]\tvalid_0's auc: 0.997656\n",
      "[312]\tvalid_0's auc: 0.997656\n",
      "[313]\tvalid_0's auc: 0.997656\n",
      "[314]\tvalid_0's auc: 0.997656\n",
      "[315]\tvalid_0's auc: 0.99778\n",
      "[316]\tvalid_0's auc: 0.99778\n",
      "[317]\tvalid_0's auc: 0.99778\n",
      "[318]\tvalid_0's auc: 0.99778\n",
      "[319]\tvalid_0's auc: 0.99778\n",
      "[320]\tvalid_0's auc: 0.99778\n",
      "[321]\tvalid_0's auc: 0.99778\n",
      "[322]\tvalid_0's auc: 0.99778\n",
      "[323]\tvalid_0's auc: 0.99778\n",
      "[324]\tvalid_0's auc: 0.99778\n",
      "[325]\tvalid_0's auc: 0.99778\n",
      "[326]\tvalid_0's auc: 0.99778\n",
      "[327]\tvalid_0's auc: 0.99778\n",
      "[328]\tvalid_0's auc: 0.997656\n",
      "[329]\tvalid_0's auc: 0.997656\n",
      "[330]\tvalid_0's auc: 0.997656\n",
      "[331]\tvalid_0's auc: 0.997656\n",
      "[332]\tvalid_0's auc: 0.997656\n",
      "[333]\tvalid_0's auc: 0.997533\n",
      "[334]\tvalid_0's auc: 0.997533\n",
      "[335]\tvalid_0's auc: 0.997533\n",
      "[336]\tvalid_0's auc: 0.997533\n",
      "[337]\tvalid_0's auc: 0.997656\n",
      "[338]\tvalid_0's auc: 0.99778\n",
      "[339]\tvalid_0's auc: 0.99778\n",
      "[340]\tvalid_0's auc: 0.99778\n",
      "[341]\tvalid_0's auc: 0.99778\n",
      "[342]\tvalid_0's auc: 0.99778\n",
      "[343]\tvalid_0's auc: 0.997903\n",
      "[344]\tvalid_0's auc: 0.997903\n",
      "[345]\tvalid_0's auc: 0.997903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[346]\tvalid_0's auc: 0.997903\n",
      "[347]\tvalid_0's auc: 0.997903\n",
      "[348]\tvalid_0's auc: 0.99778\n",
      "[349]\tvalid_0's auc: 0.99778\n",
      "[350]\tvalid_0's auc: 0.99778\n",
      "[351]\tvalid_0's auc: 0.997533\n",
      "[352]\tvalid_0's auc: 0.997533\n",
      "[353]\tvalid_0's auc: 0.997533\n",
      "[354]\tvalid_0's auc: 0.99741\n",
      "[355]\tvalid_0's auc: 0.99741\n",
      "[356]\tvalid_0's auc: 0.99741\n",
      "[357]\tvalid_0's auc: 0.99741\n",
      "[358]\tvalid_0's auc: 0.99741\n",
      "[359]\tvalid_0's auc: 0.99741\n",
      "[360]\tvalid_0's auc: 0.99741\n",
      "[361]\tvalid_0's auc: 0.99741\n",
      "[362]\tvalid_0's auc: 0.99741\n",
      "[363]\tvalid_0's auc: 0.99741\n",
      "[364]\tvalid_0's auc: 0.99741\n",
      "[365]\tvalid_0's auc: 0.99741\n",
      "[366]\tvalid_0's auc: 0.99741\n",
      "[367]\tvalid_0's auc: 0.99741\n",
      "[368]\tvalid_0's auc: 0.99741\n",
      "[369]\tvalid_0's auc: 0.99741\n",
      "[370]\tvalid_0's auc: 0.99741\n",
      "[371]\tvalid_0's auc: 0.99741\n",
      "[372]\tvalid_0's auc: 0.99741\n",
      "[373]\tvalid_0's auc: 0.99741\n",
      "[374]\tvalid_0's auc: 0.99741\n",
      "[375]\tvalid_0's auc: 0.99741\n",
      "[376]\tvalid_0's auc: 0.99741\n",
      "[377]\tvalid_0's auc: 0.99741\n",
      "[378]\tvalid_0's auc: 0.99741\n",
      "[379]\tvalid_0's auc: 0.99741\n",
      "[380]\tvalid_0's auc: 0.99741\n",
      "[381]\tvalid_0's auc: 0.99741\n",
      "[382]\tvalid_0's auc: 0.99741\n",
      "[383]\tvalid_0's auc: 0.99741\n",
      "[384]\tvalid_0's auc: 0.99741\n",
      "[385]\tvalid_0's auc: 0.99741\n",
      "[386]\tvalid_0's auc: 0.99741\n",
      "[387]\tvalid_0's auc: 0.99741\n",
      "[388]\tvalid_0's auc: 0.997533\n",
      "[389]\tvalid_0's auc: 0.997533\n",
      "[390]\tvalid_0's auc: 0.997533\n",
      "[391]\tvalid_0's auc: 0.997533\n",
      "[392]\tvalid_0's auc: 0.997533\n",
      "[393]\tvalid_0's auc: 0.997533\n",
      "[394]\tvalid_0's auc: 0.997533\n",
      "[395]\tvalid_0's auc: 0.997533\n",
      "[396]\tvalid_0's auc: 0.99741\n",
      "[397]\tvalid_0's auc: 0.99741\n",
      "[398]\tvalid_0's auc: 0.99741\n",
      "[399]\tvalid_0's auc: 0.997286\n",
      "[400]\tvalid_0's auc: 0.997286\n",
      "[401]\tvalid_0's auc: 0.99741\n",
      "[402]\tvalid_0's auc: 0.99741\n",
      "[403]\tvalid_0's auc: 0.99741\n",
      "[404]\tvalid_0's auc: 0.99741\n",
      "[405]\tvalid_0's auc: 0.99741\n",
      "[406]\tvalid_0's auc: 0.99741\n",
      "[407]\tvalid_0's auc: 0.99741\n",
      "[408]\tvalid_0's auc: 0.99741\n",
      "[409]\tvalid_0's auc: 0.997286\n",
      "[410]\tvalid_0's auc: 0.997286\n",
      "[411]\tvalid_0's auc: 0.997286\n",
      "[412]\tvalid_0's auc: 0.997286\n",
      "[413]\tvalid_0's auc: 0.997286\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's auc: 0.998643\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "The number of features in data (1) is not the same as it was in training data (30).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-fc6f614c5f46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mX_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pred'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-8f79eec305c6>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X_pred)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mtest_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstacking_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0msn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgbm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                 \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m                 \u001b[0mtest_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[0mX_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DEVTOOLS\\Anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[0;32m   2957\u001b[0m         return predictor.predict(data, start_iteration, num_iteration,\n\u001b[0;32m   2958\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2959\u001b[1;33m                                  data_has_header, is_reshape)\n\u001b[0m\u001b[0;32m   2960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2961\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DEVTOOLS\\Anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[0;32m    584\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m             \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DEVTOOLS\\Anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[1;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[0;32m    675\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m     def __create_sparse_native(self, cs, out_shape, out_ptr_indptr, out_ptr_indices, out_ptr_data,\n",
      "\u001b[1;32mD:\\DEVTOOLS\\Anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[1;34m(mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[0;32m    657\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_parameter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_num_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m                 preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[0;32m    660\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_preds\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mout_num_preds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Wrong length for predict results\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DEVTOOLS\\Anaconda3\\envs\\tf\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \"\"\"\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecode_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLightGBMError\u001b[0m: The number of features in data (1) is not the same as it was in training data (30).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing."
     ]
    }
   ],
   "source": [
    "# 测试封装的模型\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "X, y = make_gaussian_quantiles(mean=None,\n",
    "                               cov=1.0,\n",
    "                               n_samples=50,\n",
    "                               n_classes=2,\n",
    "                               shuffle=True,\n",
    "                               random_state=2)\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,\n",
    "                                                    random_state=1)\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'num_leaves': 9,\n",
    "    'learning_rate': 0.03,\n",
    "    'feature_fraction_seed': 2,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'min_data': 20,\n",
    "    'min_hessian': 1,\n",
    "    'verbose': -1,\n",
    "    'silent': 0\n",
    "}\n",
    "\n",
    "model = SBBTree(params=params,\n",
    "                stacking_num=2,\n",
    "                bagging_num=1,\n",
    "                bagging_test_size=0.33,\n",
    "                num_boost_round=10000,\n",
    "                early_stopping_rounds=200)\n",
    "model.fit(X, y)\n",
    "X_pred = X[0].reshape((-1, 1))\n",
    "pred = model.predict(X_pred)\n",
    "print('pred')\n",
    "print(pred)\n",
    "print('Test 1 OK')\n",
    "\n",
    "# test1\n",
    "model = SBBTree(params=params,\n",
    "                stacking_num=1,\n",
    "                bagging_num=1,\n",
    "                bagging_test_size=0.33,\n",
    "                num_boost_round=10000,\n",
    "                early_stopping_rounds=200)\n",
    "model.fit(X_train, y_train)\n",
    "pred1 = model.predict(X_test)\n",
    "\n",
    "# test2\n",
    "model = SBBTree(params=params,\n",
    "                stacking_num=1,\n",
    "                bagging_num=3,\n",
    "                bagging_test_size=0.33,\n",
    "                num_boost_round=10000,\n",
    "                early_stopping_rounds=200)\n",
    "model.fit(X_train, y_train)\n",
    "pred2 = model.predict(X_test)\n",
    "\n",
    "# test3\n",
    "model = SBBTree(params=params,\n",
    "                stacking_num=5,\n",
    "                bagging_num=1,\n",
    "                bagging_test_size=0.33,\n",
    "                num_boost_round=10000,\n",
    "                early_stopping_rounds=200)\n",
    "model.fit(X_train, y_train)\n",
    "pred3 = model.predict(X_test)\n",
    "\n",
    "# test4\n",
    "model = SBBTree(params=params,\n",
    "                stacking_num=5,\n",
    "                bagging_num=3,\n",
    "                bagging_test_size=0.33,\n",
    "                num_boost_round=10000,\n",
    "                early_stopping_rounds=200)\n",
    "model.fit(X_train, y_train)\n",
    "pred4 = model.predict(X_test)\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test + 1, pred1, pos_label=2)\n",
    "print('auc: ', metrics.auc(fpr, tpr))\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test + 1, pred2, pos_label=2)\n",
    "print('auc: ', metrics.auc(fpr, tpr))\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test + 1, pred3, pos_label=2)\n",
    "print('auc: ', metrics.auc(fpr, tpr))\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y_test + 1, pred4, pos_label=2)\n",
    "print('auc: ', metrics.auc(fpr, tpr))\n",
    "\n",
    "pred = model.predict(test)\n",
    "df_out = pd.DataFrame()\n",
    "df_out['user_id'] = test_data['user_id']\n",
    "df_out['predict_prob'] = pred\n",
    "df_out.head()\n",
    "\n",
    "df_out.to_csv('df_out.csv', header=True, index=False)\n",
    "print('save OK!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-09T08:33:00.146Z"
    }
   },
   "source": [
    "# 模型优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T10:10:55.674953Z",
     "start_time": "2021-07-12T10:10:41.359432Z"
    }
   },
   "outputs": [],
   "source": [
    "#  导入数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 读取前1000行\n",
    "# train_data = pd.read_csv('train_all.csv', nrows=1000)\n",
    "# test_data = pd.read_csv('test_all.csv', nrows=1000)\n",
    "\n",
    "# 读取全部数据\n",
    "train_data = pd.read_csv('train_all.csv', nrows=None)\n",
    "test_data = pd.read_csv('test_all.csv', nrows=None)\n",
    "\n",
    "# 训练数据和测试数据处理\n",
    "feature_columns = [col for col in train_data.columns if col not in ['user_id', 'label']]\n",
    "train = train_data[feature_columns].values\n",
    "test = test_data[feature_columns].values\n",
    "target = train_data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T10:10:55.704936Z",
     "start_time": "2021-07-12T10:10:55.676952Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def feature_selection(train, train_sel, target):\n",
    "    \"\"\"\n",
    "    特征选择效果对比\n",
    "    :param train: 未做特征选择的训练集\n",
    "    :param train_sel: 已做特征选择的训练集\n",
    "    :param target: 目标集\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    clf = RandomForestClassifier(n_estimators=100,\n",
    "                                 max_depth=2,\n",
    "                                 random_state=0,\n",
    "                                 n_jobs=-1)\n",
    "    scores = cross_val_score(estimator=clf, X=train, y=target, cv=5)\n",
    "    scores_sel = cross_val_score(estimator=clf, X=train_sel, y=target, cv=5)\n",
    "    print('No Select Accuracy: %0.2f (+/- %0.2f)' % (scores.mean(), scores.std() * 2))\n",
    "    print('Select Accuracy: %0.2f (+/- %0.2f)' % (scores_sel.mean(), scores_sel.std() * 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T10:11:01.990242Z",
     "start_time": "2021-07-12T10:10:55.706935Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 缺失值填充\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "imputer = imputer.fit(train)\n",
    "train_imputer = imputer.transform(train)\n",
    "test_imputer = imputer.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T10:11:30.479875Z",
     "start_time": "2021-07-12T10:11:01.992241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据未特征选择维度 (260864, 230)\n",
      "训练数据特征选择维度 (260864, 25)\n",
      "No Select Accuracy: 0.94 (+/- 0.00)\n",
      "Select Accuracy: 0.94 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 删除方差较小的特征\n",
    "sel = VarianceThreshold(threshold=(0.8 * (1 - 0.8)))\n",
    "sel = sel.fit(train)\n",
    "train_sel = sel.transform(train)\n",
    "test_sel = sel.transform(test)\n",
    "print('训练数据未特征选择维度', train.shape)\n",
    "print('训练数据特征选择维度', train_sel.shape)\n",
    "\n",
    "feature_selection(train, train_sel, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T10:28:33.396618Z",
     "start_time": "2021-07-12T10:11:30.481874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据未特征选择维度 (260864, 230)\n",
      "训练数据特征选择维度 (260864, 2)\n",
      "No Select Accuracy: 0.94 (+/- 0.00)\n",
      "Select Accuracy: 0.94 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "# 单变量特征选择\n",
    "sel = SelectKBest(score_func=mutual_info_classif, k=2)\n",
    "sel = sel.fit(train, target)\n",
    "train_sel = sel.transform(train)\n",
    "test_sel = sel.transform(test)\n",
    "print('训练数据未特征选择维度', train.shape)\n",
    "print('训练数据特征选择维度', train_sel.shape)\n",
    "\n",
    "feature_selection(train, train_sel, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T10:46:54.312863Z",
     "start_time": "2021-07-12T10:37:38.308621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据未特征选择维度 (260864, 230)\n",
      "训练数据特征选择维度 (260864, 1)\n",
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False  True]\n",
      "[230 229 228 227 225 223 220 216 207 205 204 202 201 200 199 198 197 196\n",
      " 195 193 192 187 185 178 175 172 170 169 168 166 165 164 163 161 160 159\n",
      " 155 154 153 150 149 148 147 146 144 143 142 140 139 137 136 135 134 133\n",
      " 117 115 114 113 108 107 105 104 103 101  96  92  91  90  88  87  84  82\n",
      "  81  80  77  75  74  73  72  71  70  53  43  38  37  28  26   4   3   8\n",
      "  11  19   6   5   7  16  18  22  23  40  42  30  45  31  54  46  58  34\n",
      "  56  50  60 208 210 212 214 218 226 224 222 221 219 217 215 213 211 209\n",
      " 206 176 203 180 182 188 194 190 191 189 186 184 183 181 179 177 174 173\n",
      " 171  94 167 118 162 156 158 157 120 152 151 122 124 145 126 141 138 128\n",
      " 130 132 131 129 127 125 123 121 119 116 110 112 111 109 106  98 102 100\n",
      "  99  97  95  93  62  89  86  85  83  78  79  76  64  66  68  69  67  65\n",
      "  63  61  59  57  55  52  51  49  41  39  36  35  33  29  27  25  21  17\n",
      "  15  14  32  44  13  12  48  10  24   9  47  20   2   1]\n",
      "No Select Accuracy: 0.94 (+/- 0.00)\n",
      "Select Accuracy: 0.94 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "# 递归功能消除\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=10,\n",
    "                             max_depth=2,\n",
    "                             random_state=0,\n",
    "                             n_jobs=-1)\n",
    "\n",
    "selector = RFECV(estimator=clf, step=1, cv=2)\n",
    "selector = selector.fit(train, target)\n",
    "train_sel = selector.transform(train)\n",
    "test_sel = selector.transform(test)\n",
    "print('训练数据未特征选择维度', train.shape)\n",
    "print('训练数据特征选择维度', train_sel.shape)\n",
    "print(selector.support_)\n",
    "print(selector.ranking_)\n",
    "\n",
    "feature_selection(train, train_sel, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T10:46:55.419230Z",
     "start_time": "2021-07-12T10:46:54.314862Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "when `importance_getter=='auto'`, the underlying estimator LogisticRegression should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-7294ba90a129>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mLR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSelectFromModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtrain_sel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mtest_sel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'训练数据未特征选择维度'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DEVTOOLS\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\feature_selection\\_base.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0m_safe_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"allow_nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         )\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             warn(\"No features were selected: either the data is\"\n",
      "\u001b[1;32mD:\\DEVTOOLS\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\feature_selection\\_base.py\u001b[0m in \u001b[0;36mget_support\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0mare\u001b[0m \u001b[0mindices\u001b[0m \u001b[0minto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mvector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \"\"\"\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_support_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DEVTOOLS\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\feature_selection\\_from_model.py\u001b[0m in \u001b[0;36m_get_support_mask\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    188\u001b[0m         scores = _get_feature_importances(\n\u001b[0;32m    189\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimportance_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             transform_func='norm', norm_order=self.norm_order)\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_calculate_threshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DEVTOOLS\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\feature_selection\\_base.py\u001b[0m in \u001b[0;36m_get_feature_importances\u001b[1;34m(estimator, getter, transform_func, norm_order)\u001b[0m\n\u001b[0;32m    172\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m                 raise ValueError(\n\u001b[1;32m--> 174\u001b[1;33m                     \u001b[1;34mf\"when `importance_getter=='auto'`, the underlying \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m                     \u001b[1;34mf\"estimator {estimator.__class__.__name__} should have \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                     \u001b[1;34mf\"`coef_` or `feature_importances_` attribute. Either \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: when `importance_getter=='auto'`, the underlying estimator LogisticRegression should have `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to feature selector or call fit before calling transform."
     ]
    }
   ],
   "source": [
    "# 使用模型选择特征\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "normalizer = Normalizer()\n",
    "normalizer = normalizer.fit(train)\n",
    "train_norm = normalizer.transform(train)\n",
    "test_norm = normalizer.transform(test)\n",
    "LR = LogisticRegression(penalty='l2', C=5)\n",
    "model = SelectFromModel(estimator=LR, prefit=True)\n",
    "train_sel = model.transform(train)\n",
    "test_sel = model.transform(test)\n",
    "print('训练数据未特征选择维度', train.shape)\n",
    "print('训练数据特征选择维度', train_sel.shape)\n",
    "\n",
    "feature_selection(train, train_sel, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-12T10:46:55.421229Z",
     "start_time": "2021-07-12T10:37:44.406Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用树模型选择特征\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "clf = clf.fit(X=train, y=target)\n",
    "model = SelectFromModel(estimator=clf, prefit=True)\n",
    "train_sel = model.transform(train)\n",
    "test_sel = model.transform(test)\n",
    "print('训练数据未特征选择维度', train.shape)\n",
    "print('训练数据特征选择维度', train_sel.shape)\n",
    "\n",
    "feature_selection(train, train_sel, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
